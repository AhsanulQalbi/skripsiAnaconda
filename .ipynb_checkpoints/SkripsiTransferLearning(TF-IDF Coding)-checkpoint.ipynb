{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKRIPSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk import ngrams\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, validation_curve,RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from matplotlib_venn import venn2\n",
    "from time import time\n",
    "\n",
    "np.random.seed(0)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "poster_Stemmer = nltk.PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baca file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baca csv\n",
    "data_train_amazon = pd.read_csv('Amazon_Train.csv')\n",
    "data_train_yelp = pd.read_csv('Yelp_Train.csv')\n",
    "data_test_amazon = pd.read_csv('Amazon_Test.csv')\n",
    "data_test_yelp = pd.read_csv('Yelp_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label                                           Sentimen\n",
      "0      0  Buyer beware This is a self-published book, an...\n",
      "1      0  The Worst! A complete waste of time. Typograph...\n",
      "2      0  Oh please I guess you have to be a romance nov...\n",
      "3      0  Awful beyond belief! I feel I have to write to...\n",
      "4      0  Another Abysmal Digital Copy Rather than scrat...\n",
      "\n",
      "\n",
      "   Label                                           Sentimen\n",
      "0      0  I don't know what Dr. Goldberg was like before...\n",
      "1      0  I'm writing this review to give you a heads up...\n",
      "2      0  Owning a driving range inside the city limits ...\n",
      "3      0  This place is absolute garbage...  Half of the...\n",
      "4      0  Used to go there for tires, brakes, etc.  Thei...\n"
     ]
    }
   ],
   "source": [
    "print(data_train_amazon.head())\n",
    "print(\"\\n\")\n",
    "print(data_train_yelp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label                                           Sentimen\n",
      "0      0  Overly complicated Being both a U.S. history b...\n",
      "1      0  Terrible Disappointment -- parts don't fit My ...\n",
      "2      0  Didn't hold up.....very disappointed I bought ...\n",
      "3      0  gene hates jezebel i love JLJ but this compila...\n",
      "4      0  Nice toy but ... My six-year-old loves space a...\n",
      "\n",
      "\n",
      "   Label                                           Sentimen\n",
      "0      0  My wife and I used to love Arriba's, til recen...\n",
      "1      0  You get what you pay for.  The food is inexpen...\n",
      "2      0  Unfortunately, yesterday's visit was one of th...\n",
      "3      0  I went into the Scottsdale location yesterday....\n",
      "4      0  It takes a lot for me to write a review and bl...\n"
     ]
    }
   ],
   "source": [
    "print(data_test_amazon.head())\n",
    "print(\"\\n\")\n",
    "print(data_test_yelp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Preprocessing_Amazon_Train = data_train_amazon.Sentimen.astype(str)\n",
    "data_Preprocessing_Amazon_Train = data_Preprocessing_Amazon_Train.apply(lambda x: x.lower())\n",
    "data_Preprocessing_Amazon_Train = data_Preprocessing_Amazon_Train.apply(lambda x: re.sub(r\"\\d\", \"\", x))   \n",
    "data_Preprocessing_Amazon_Train = data_Preprocessing_Amazon_Train.apply(lambda x: x.translate(str.maketrans('','',string.punctuation))) #punctuation  \n",
    "data_Preprocessing_Amazon_Train = data_Preprocessing_Amazon_Train.apply(lambda x: \" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
    "\n",
    "data_Preprocessing_Yelp_Train = data_train_yelp.Sentimen.astype(str)\n",
    "data_Preprocessing_Yelp_Train = data_Preprocessing_Yelp_Train.apply(lambda x: x.lower())\n",
    "data_Preprocessing_Yelp_Train = data_Preprocessing_Yelp_Train.apply(lambda x: re.sub(r\"\\d\", \"\", x))   \n",
    "data_Preprocessing_Yelp_Train = data_Preprocessing_Yelp_Train.apply(lambda x: x.translate(str.maketrans('','',string.punctuation))) #punctuation  \n",
    "data_Preprocessing_Yelp_Train = data_Preprocessing_Yelp_Train.apply(lambda x: \" \".join(re.findall(\"[a-zA-Z]+\", x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    buyer beware this is a selfpublished book and ...\n",
       "1    the worst a complete waste of time typographic...\n",
       "2    oh please i guess you have to be a romance nov...\n",
       "3    awful beyond belief i feel i have to write to ...\n",
       "4    another abysmal digital copy rather than scrat...\n",
       "Name: Sentimen, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i dont know what dr goldberg was like before m...\n",
       "1    im writing this review to give you a heads up ...\n",
       "2    owning a driving range inside the city limits ...\n",
       "3    this place is absolute garbage half of the tee...\n",
       "4    used to go there for tires brakes etc their pr...\n",
       "Name: Sentimen, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Preprocessing_Amazon_Test = data_test_amazon.Sentimen.astype(str)\n",
    "data_Preprocessing_Amazon_Test = data_Preprocessing_Amazon_Test.apply(lambda x: x.lower())\n",
    "data_Preprocessing_Amazon_Test = data_Preprocessing_Amazon_Test.apply(lambda x: re.sub(r\"\\d\", \"\", x))   \n",
    "data_Preprocessing_Amazon_Test = data_Preprocessing_Amazon_Test.apply(lambda x: x.translate(str.maketrans('','',string.punctuation))) #punctuation  \n",
    "data_Preprocessing_Amazon_Test = data_Preprocessing_Amazon_Test.apply(lambda x: \" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
    "\n",
    "data_Preprocessing_Yelp_Test = data_test_yelp.Sentimen.astype(str)\n",
    "data_Preprocessing_Yelp_Test = data_Preprocessing_Yelp_Test.apply(lambda x: x.lower())\n",
    "data_Preprocessing_Yelp_Test = data_Preprocessing_Yelp_Test.apply(lambda x: re.sub(r\"\\d\", \"\", x))   \n",
    "data_Preprocessing_Yelp_Test = data_Preprocessing_Yelp_Test.apply(lambda x: x.translate(str.maketrans('','',string.punctuation))) #punctuation  \n",
    "data_Preprocessing_Yelp_Test = data_Preprocessing_Yelp_Test.apply(lambda x: \" \".join(re.findall(\"[a-zA-Z]+\", x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    overly complicated being both a us history buf...\n",
       "1    terrible disappointment parts dont fit my son ...\n",
       "2    didnt hold upvery disappointed i bought this o...\n",
       "3    gene hates jezebel i love jlj but this compila...\n",
       "4    nice toy but my sixyearold loves space and to ...\n",
       "Name: Sentimen, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    my wife and i used to love arribas til recentl...\n",
       "1    you get what you pay for the food is inexpensi...\n",
       "2    unfortunately yesterdays visit was one of the ...\n",
       "3    i went into the scottsdale location yesterday ...\n",
       "4    it takes a lot for me to write a review and bl...\n",
       "Name: Sentimen, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_Amazon_Sentiment_Train = data_Preprocessing_Amazon_Train\n",
    "Clean_Yelp_Sentiment_Train = data_Preprocessing_Yelp_Train\n",
    "Label_Amazon_Train = data_train_amazon['Label']\n",
    "Label_Yelp_Train = data_train_yelp['Label']\n",
    "\n",
    "Clean_Amazon_Sentiment_Test = data_Preprocessing_Amazon_Test\n",
    "Clean_Yelp_Sentiment_Test = data_Preprocessing_Yelp_Test\n",
    "Label_Amazon_Test = data_test_amazon['Label']\n",
    "Label_Yelp_Test = data_test_yelp['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram (bigram dan trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_trigram(Clean_Sentiment) :\n",
    "    iterator = 0\n",
    "    Vocabulary = []\n",
    "    ngram_result = []\n",
    "    while iterator < len(Clean_Sentiment) :\n",
    "        ngram = 2\n",
    "        sentence = Clean_Sentiment[iterator]\n",
    "        vocab = [sentence[i:i+ngram] for i in range(len(sentence)-ngram+1)]\n",
    "        temp = vocab\n",
    "\n",
    "        iterator2 = 0\n",
    "        while iterator2 < len (vocab):\n",
    "            if(vocab[iterator2] not in Vocabulary) :\n",
    "                Vocabulary.append(vocab[iterator2])\n",
    "            iterator2 = iterator2 + 1\n",
    "\n",
    "        ngram = 3\n",
    "        vocab = [sentence[i:i+ngram] for i in range(len(sentence)-ngram+1)]\n",
    "        temp = temp + vocab\n",
    "        ngram_result.append(temp)\n",
    "        iterator2 = 0\n",
    "        while iterator2 < len (vocab):\n",
    "            if(vocab[iterator2] not in Vocabulary) :\n",
    "                Vocabulary.append(vocab[iterator2])\n",
    "            iterator2 = iterator2 + 1\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    return ngram_result,Vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_amazon_train, Vocabulary_Amazon_Train = bigram_trigram(Clean_Amazon_Sentiment_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_yelp_train, Vocabulary_Yelp_Train = bigram_trigram(Clean_Yelp_Sentiment_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_amazon_test, Vocabulary_Amazon_Test = bigram_trigram(Clean_Amazon_Sentiment_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_yelp_test, Vocabulary_Yelp_Test = bigram_trigram(Clean_Yelp_Sentiment_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Me inisialisasi jumlah frekuensi Gram di Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionaryInitialize(Clean_Sentiment, Vocabulary, ngram, jenisdata) :\n",
    "    wordDictionaryCount = []\n",
    "    iterator = 0\n",
    "    while iterator < len(Clean_Sentiment):\n",
    "        wordDictionaryCount.append(dict.fromkeys(Vocabulary , 0))\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    iterator = 0\n",
    "    \n",
    "    while iterator < len(Clean_Sentiment) :\n",
    "        for gram in ngram[iterator] :\n",
    "            if jenisdata == 'test' and gram not in Vocabulary :\n",
    "                continue\n",
    "            wordDictionaryCount[iterator][gram] += 1\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    return wordDictionaryCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordDictionaryCount_Amazon_Train = dictionaryInitialize(Clean_Amazon_Sentiment_Train, Vocabulary_Amazon_Train, ngram_amazon_train,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordDictionaryCount_Yelp_Train = dictionaryInitialize(Clean_Yelp_Sentiment_Train, Vocabulary_Yelp_Train, ngram_yelp_train,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordDictionaryCount_Amazon_Test = dictionaryInitialize(Clean_Amazon_Sentiment_Test, Vocabulary_Amazon_Train, ngram_amazon_test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordDictionaryCount_Yelp_Test = dictionaryInitialize(Clean_Yelp_Sentiment_Test, Vocabulary_Yelp_Train, ngram_yelp_test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bu</th>\n",
       "      <th>uy</th>\n",
       "      <th>ye</th>\n",
       "      <th>er</th>\n",
       "      <th>r</th>\n",
       "      <th>b</th>\n",
       "      <th>be</th>\n",
       "      <th>ew</th>\n",
       "      <th>wa</th>\n",
       "      <th>ar</th>\n",
       "      <th>...</th>\n",
       "      <th>umy</th>\n",
       "      <th>myu</th>\n",
       "      <th>mmc</th>\n",
       "      <th>sez</th>\n",
       "      <th>fja</th>\n",
       "      <th>coz</th>\n",
       "      <th>ozy</th>\n",
       "      <th>kav</th>\n",
       "      <th>gju</th>\n",
       "      <th>ukw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 9321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bu  uy  ye  er  r    b  be  ew  wa  ar  ...  umy  myu  mmc  sez  fja  coz  \\\n",
       "0   1   1   1  11   9  13   5   3   4   7  ...    0    0    0    0    0    0   \n",
       "1   0   0   0   2   5   1   0   0   1   2  ...    0    0    0    0    0    0   \n",
       "\n",
       "   ozy  kav  gju  ukw  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "\n",
       "[2 rows x 9321 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([WordDictionaryCount_Amazon_Train[0],WordDictionaryCount_Amazon_Train[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>d</th>\n",
       "      <th>do</th>\n",
       "      <th>on</th>\n",
       "      <th>nt</th>\n",
       "      <th>t</th>\n",
       "      <th>k</th>\n",
       "      <th>kn</th>\n",
       "      <th>no</th>\n",
       "      <th>ow</th>\n",
       "      <th>...</th>\n",
       "      <th>nhg</th>\n",
       "      <th>hgn</th>\n",
       "      <th>nwc</th>\n",
       "      <th>sez</th>\n",
       "      <th>ffb</th>\n",
       "      <th>fbe</th>\n",
       "      <th>yec</th>\n",
       "      <th>nww</th>\n",
       "      <th>zeg</th>\n",
       "      <th>ypu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 9399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   i    d  do  on  nt  t    k  kn  no  ow  ...  nhg  hgn  nwc  sez  ffb  fbe  \\\n",
       "0   4  11   6  13   7  19   1   1   5   1  ...    0    0    0    0    0    0   \n",
       "1  10   7   6  10  13  21   1   1   1   1  ...    0    0    0    0    0    0   \n",
       "\n",
       "   yec  nww  zeg  ypu  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "\n",
       "[2 rows x 9399 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([WordDictionaryCount_Yelp_Train[0],WordDictionaryCount_Yelp_Train[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung nilai TF pada setiap data Amazon dan Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFrequency(wordDict, ngram):\n",
    "    freqword = {}\n",
    "    ngramLength = len(ngram)\n",
    "    for word, count in wordDict.items():\n",
    "        freqword[word] = count\n",
    "    return freqword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrequencyTermPerData(wordDictionary, ngram) :\n",
    "    CountFrequency = []\n",
    "    iterator = 0\n",
    "    while iterator < len(ngram):\n",
    "        CountFrequency.append(computeFrequency(wordDictionary[iterator], ngram[iterator]))\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    return CountFrequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountFrequency_Sentimen_Amazon_Train = getFrequencyTermPerData(WordDictionaryCount_Amazon_Train, ngram_amazon_train)\n",
    "CountFrequency_Sentimen_Yelp_Train = getFrequencyTermPerData(WordDictionaryCount_Yelp_Train, ngram_yelp_train)\n",
    "CountFrequency_Sentimen_Amazon_Test = getFrequencyTermPerData(WordDictionaryCount_Amazon_Test, ngram_amazon_test)\n",
    "CountFrequency_Sentimen_Yelp_Test = getFrequencyTermPerData(WordDictionaryCount_Yelp_Test, ngram_yelp_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung nilai IDF pada setiap data Amazon dan Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(WordDict):\n",
    "    idfDict = {}\n",
    "    number_of_document_with_term_t_in_it = {}\n",
    "    N = len(WordDict)\n",
    "    \n",
    "    idfDict = dict.fromkeys(WordDict[0].keys(), 0)\n",
    "    for doc in WordDict:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        number_of_document_with_term_t_in_it[word] = float(val)\n",
    "        idfDict[word] = np.log((1+N) / (1+val)) + 1\n",
    "        \n",
    "    return idfDict, number_of_document_with_term_t_in_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF_Amazon, number_of_document_with_term_t_Amazon_Train = computeIDF(WordDictionaryCount_Amazon_Train)\n",
    "IDF_Yelp, number_of_document_with_term_t_in_Yelp_Train = computeIDF(WordDictionaryCount_Yelp_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDFnonScale(CountFrequency, idfs):\n",
    "    tfidf = None\n",
    "    tfidf = {}\n",
    "    for word, val in CountFrequency.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfidf_nonscaled) :\n",
    "    tfidf_nonscaled = np.array(tfidf_nonscaled)\n",
    "    tfidf_list = tfidf_nonscaled/sum(tfidf_nonscaled**2)**0.5\n",
    "    return tfidf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getTFIDFnonScale(WordDictionary, CountFrequency, IDF):\n",
    "#     iterator = 0\n",
    "#     TFIDFnonscale = []\n",
    "#     while iterator < len(WordDictionary):\n",
    "#         TFIDFnonscale.append(computeTFIDFnonScale(CountFrequency[iterator], IDF))\n",
    "#         iterator = iterator + 1\n",
    "    \n",
    "#     return TFIDFnonscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF_nonScale_Amazon_Train = getTFIDFnonScale(WordDictionaryCount_Amazon_Train, CountFrequency_Sentimen_Amazon_Train, IDF_Amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF_nonScale_Amazon_Test = getTFIDFnonScale(WordDictionaryCount_Amazon_Test, CountFrequency_Sentimen_Amazon_Test, IDF_Amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFIDF(wordDictionary, CountFrequency, IDF):\n",
    "    TFIDF_non_scaled = None\n",
    "    TFIDF_non_scaled = []\n",
    "    iterator = 0\n",
    "    while iterator < len(wordDictionary):\n",
    "        TFIDF_non_scaled.append(computeTFIDFnonScale(CountFrequency[iterator], IDF))\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    TFIDF = []\n",
    "    iterator = 0\n",
    "    while iterator < len(wordDictionary):\n",
    "        tf_idf_list = list(TFIDF_non_scaled[iterator].values())\n",
    "        TFIDF.append(computeTFIDF(tf_idf_list))\n",
    "        iterator = iterator + 1\n",
    "        \n",
    "    return TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_Amazon_Train = getTFIDF(WordDictionaryCount_Amazon_Train, CountFrequency_Sentimen_Amazon_Train, IDF_Amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_Amazon_Test = getTFIDF(WordDictionaryCount_Amazon_Test, CountFrequency_Sentimen_Amazon_Test, IDF_Amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_Yelp_Train = getTFIDF(WordDictionaryCount_Yelp_Train, CountFrequency_Sentimen_Yelp_Train, IDF_Yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_Yelp_Test = getTFIDF(WordDictionaryCount_Yelp_Test, CountFrequency_Sentimen_Yelp_Test, IDF_Yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toVectorizeList(TFIDF):\n",
    "    iterator  = 0\n",
    "    Vectorized = []\n",
    "    while iterator < len(TFIDF):\n",
    "        Vectorized.append(list(TFIDF[iterator]))\n",
    "        iterator = iterator + 1\n",
    "    return Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer_Amazon_Train = toVectorizeList(TFIDF_Amazon_Train)\n",
    "Vectorizer_Amazon_Test = toVectorizeList(TFIDF_Amazon_Test)\n",
    "Vectorizer_Yelp_Train = toVectorizeList(TFIDF_Yelp_Train)\n",
    "Vectorizer_Yelp_Test = toVectorizeList(TFIDF_Yelp_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a    aa        ab        ac        ad   ae        af  \\\n",
      "0     0.174884  0.079896  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "1     0.149341  0.046906  0.0  0.044125  0.052581  0.055971  0.0  0.000000   \n",
      "2     0.122904  0.056149  0.0  0.026410  0.000000  0.000000  0.0  0.033775   \n",
      "3     0.107078  0.041393  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "4     0.121365  0.022871  0.0  0.014344  0.017092  0.000000  0.0  0.000000   \n",
      "...        ...       ...  ...       ...       ...       ...  ...       ...   \n",
      "7495  0.082949  0.014887  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "7496  0.119551  0.033377  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "7497  0.139474  0.087614  0.0  0.029971  0.000000  0.000000  0.0  0.000000   \n",
      "7498  0.103292  0.000000  0.0  0.000000  0.072736  0.000000  0.0  0.000000   \n",
      "7499  0.040737  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "\n",
      "            ag   ah  ...  zzf  zzi  zzk  zzl  zzo  zzs  zzt  zzu  zzy  zzz  \n",
      "0     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.024274  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "7495  0.034922  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7496  0.039147  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7497  0.037367  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7498  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7499  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[7500 rows x 9321 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Amazon_Train = pd.DataFrame(Vectorizer_Amazon_Train, columns = Vocabulary_Amazon_Train)\n",
    "DataFrame_Amazon_Train = DataFrame_Amazon_Train.reindex(sorted(DataFrame_Amazon_Train.columns), axis=1)\n",
    "print (DataFrame_Amazon_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a    aa        ab   ac        ad   ae        af  \\\n",
      "0     0.145900  0.061100  0.0  0.019159  0.0  0.048606  0.0  0.024502   \n",
      "1     0.087064  0.013673  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2     0.090990  0.048992  0.0  0.015362  0.0  0.000000  0.0  0.039293   \n",
      "3     0.086429  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "4     0.085100  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "...        ...       ...  ...       ...  ...       ...  ...       ...   \n",
      "2495  0.048423  0.015209  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2496  0.051493  0.021564  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2497  0.109906  0.046027  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2498  0.033166  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2499  0.089913  0.045185  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "\n",
      "            ag   ah  ...  zzf  zzi  zzk  zzl  zzo  zzs  zzt  zzu  zzy  zzz  \n",
      "0     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "2495  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2496  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2497  0.053983  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2498  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2499  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2500 rows x 9321 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Amazon_Test = pd.DataFrame(Vectorizer_Amazon_Test, columns = Vocabulary_Amazon_Train)\n",
    "DataFrame_Amazon_Test = DataFrame_Amazon_Test.reindex(sorted(DataFrame_Amazon_Test.columns), axis=1)\n",
    "print (DataFrame_Amazon_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a    aa        ab       ac        ad   ae        af  \\\n",
      "0     0.171214  0.048025  0.0  0.036015  0.00000  0.017194  0.0  0.014425   \n",
      "1     0.140388  0.044025  0.0  0.012840  0.00000  0.036779  0.0  0.000000   \n",
      "2     0.159648  0.054833  0.0  0.011994  0.04579  0.017178  0.0  0.000000   \n",
      "3     0.190184  0.025403  0.0  0.022225  0.00000  0.000000  0.0  0.026706   \n",
      "4     0.059365  0.035682  0.0  0.000000  0.00000  0.000000  0.0  0.000000   \n",
      "...        ...       ...  ...       ...      ...       ...  ...       ...   \n",
      "7495  0.103979  0.031249  0.0  0.000000  0.00000  0.000000  0.0  0.000000   \n",
      "7496  0.157036  0.043564  0.0  0.000000  0.00000  0.000000  0.0  0.000000   \n",
      "7497  0.043994  0.000000  0.0  0.000000  0.00000  0.000000  0.0  0.000000   \n",
      "7498  0.061627  0.000000  0.0  0.000000  0.00000  0.000000  0.0  0.000000   \n",
      "7499  0.170437  0.083817  0.0  0.016296  0.00000  0.000000  0.0  0.019582   \n",
      "\n",
      "       ag   ah  ...  zzb  zzc  zze  zzi  zzl  zzn  zzo  zzu  zzy  zzz  \n",
      "0     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "7495  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7496  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7497  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7498  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7499  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[7500 rows x 9399 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Yelp_Train = pd.DataFrame(Vectorizer_Yelp_Train, columns = Vocabulary_Yelp_Train)\n",
    "DataFrame_Yelp_Train = DataFrame_Yelp_Train.reindex(sorted(DataFrame_Yelp_Train.columns), axis=1)\n",
    "print (DataFrame_Yelp_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a    aa        ab        ac        ad   ae        af  \\\n",
      "0     0.164301  0.026335  0.0  0.023041  0.000000  0.000000  0.0  0.013843   \n",
      "1     0.078854  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "2     0.090357  0.046551  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "3     0.120136  0.009628  0.0  0.000000  0.000000  0.000000  0.0  0.020244   \n",
      "4     0.164085  0.024055  0.0  0.000000  0.000000  0.000000  0.0  0.010116   \n",
      "...        ...       ...  ...       ...       ...       ...  ...       ...   \n",
      "2495  0.120832  0.016139  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "2496  0.090460  0.036248  0.0  0.000000  0.000000  0.090846  0.0  0.000000   \n",
      "2497  0.181204  0.019803  0.0  0.000000  0.000000  0.000000  0.0  0.041637   \n",
      "2498  0.169448  0.040739  0.0  0.011881  0.015120  0.000000  0.0  0.014276   \n",
      "2499  0.154315  0.037101  0.0  0.000000  0.041309  0.000000  0.0  0.000000   \n",
      "\n",
      "            ag      ah  ...  zzb  zzc  zze  zzi  zzl  zzn  zzo  zzu  zzy  zzz  \n",
      "0     0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.030708  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...        ...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "2495  0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2496  0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2497  0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2498  0.000000  0.0273  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2499  0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2500 rows x 9399 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Yelp_Test = pd.DataFrame(Vectorizer_Yelp_Test, columns = Vocabulary_Yelp_Train)\n",
    "DataFrame_Yelp_Test = DataFrame_Yelp_Test.reindex(sorted(DataFrame_Yelp_Test.columns), axis=1)\n",
    "print (DataFrame_Yelp_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Akurasi dan Waktu Train Test Amazon dan Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waktu Training Amazon: 54.958s\n"
     ]
    }
   ],
   "source": [
    "Waktu_Training = time()\n",
    "RF_Classifier_Amazon = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Amazon.fit(Vectorizer_Amazon_Train, Label_Amazon_Train)\n",
    "print(f\"\\nWaktu Training Amazon: {round(time()-Waktu_Training, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waktu prediksi (train): 6.103s\n",
      "waktu prediksi (test): 2.092s\n",
      "\n",
      "Skor Random Forest Train Amazon : 0.8589333333333333\n",
      "Skor Random Forest Test Amazon : 0.8072\n"
     ]
    }
   ],
   "source": [
    "Waktu_Predict_Train = time()\n",
    "Skor_Train_Amazon = RF_Classifier_Amazon.score(Vectorizer_Amazon_Train, Label_Amazon_Train)\n",
    "print(f\"waktu prediksi (train): {round(time()-Waktu_Predict_Train, 3)}s\")\n",
    "\n",
    "Waktu_Predict_Test = time()\n",
    "Skor_Test_Amazon = RF_Classifier_Amazon.score(Vectorizer_Amazon_Test, Label_Amazon_Test)\n",
    "print(f\"waktu prediksi (test): {round(time()-Waktu_Predict_Test, 3)}s\")\n",
    "\n",
    "print(\"\\nSkor Random Forest Train Amazon : {}\".format(Skor_Train_Amazon))\n",
    "print(\"Skor Random Forest Test Amazon : {}\".format(Skor_Test_Amazon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waktu Training Yelp: 59.267s\n"
     ]
    }
   ],
   "source": [
    "Waktu_Training = time()\n",
    "RF_Classifier_Yelp = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Yelp.fit(Vectorizer_Yelp_Train, Label_Yelp_Train)\n",
    "print(f\"\\nWaktu Training Yelp: {round(time()-Waktu_Training, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waktu prediksi (train): 6.649s\n",
      "waktu prediksi (test): 2.228s\n",
      "\n",
      "Skor Random Forest Train Yelp : 0.8698666666666667\n",
      "Skor Random Forest Test Yelp : 0.8424\n"
     ]
    }
   ],
   "source": [
    "Waktu_Predict_Train = time()\n",
    "Skor_Train_Yelp = RF_Classifier_Yelp.score(Vectorizer_Yelp_Train, Label_Yelp_Train)\n",
    "print(f\"waktu prediksi (train): {round(time()-Waktu_Predict_Train, 3)}s\")\n",
    "\n",
    "Waktu_Predict_Test = time()\n",
    "Skor_Test_Yelp = RF_Classifier_Yelp.score(Vectorizer_Yelp_Test, Label_Yelp_Test)\n",
    "print(f\"waktu prediksi (test): {round(time()-Waktu_Predict_Test, 3)}s\")\n",
    "\n",
    "print(\"\\nSkor Random Forest Train Yelp : {}\".format(Skor_Train_Yelp))\n",
    "print(\"Skor Random Forest Test Yelp : {}\".format(Skor_Test_Yelp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mencari Term-Term yang interseksi antara Amazon dan Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_Intersection = []\n",
    "iterator = 0\n",
    "while iterator < len(Vocabulary_Yelp_Train) :\n",
    "    if Vocabulary_Yelp_Train[iterator] in Vocabulary_Amazon_Train :\n",
    "        Vocabulary_Intersection.append(Vocabulary_Yelp_Train[iterator])\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecomputeIDF(WordDictAmazon, WordDictYelp, additional_term_value, Vocabulary_Intersection):\n",
    "    idfDict = {}\n",
    "    number_of_document_with_term_t_in_it = {}\n",
    "    N = len(WordDictYelp) + len(WordDictAmazon)\n",
    "    idfDict = dict.fromkeys(WordDictYelp[0].keys(), 0)\n",
    "    for doc in WordDictYelp:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        if word in Vocabulary_Intersection :\n",
    "            val = val + additional_term_value[word]\n",
    "        idfDict[word] = np.log((1+N) / (1+val)) + 1\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_IDF_Yelp = RecomputeIDF(WordDictionaryCount_Amazon_Train, WordDictionaryCount_Yelp_Train, number_of_document_with_term_t_Amazon_Train, Vocabulary_Intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_TFIDF_nonScale_Yelp_Train = []\n",
    "iterator = 0\n",
    "while iterator < len(WordDictionaryCount_Yelp_Train):\n",
    "    New_TFIDF_nonScale_Yelp_Train.append(computeTFIDFnonScale(CountFrequency_Sentimen_Yelp_Train[iterator], New_IDF_Yelp))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_TFIDF_Yelp_Train = []\n",
    "iterator = 0\n",
    "while iterator < len(WordDictionaryCount_Yelp_Train):\n",
    "    tf_idf_list = list(New_TFIDF_nonScale_Yelp_Train[iterator].values())\n",
    "    New_TFIDF_Yelp_Train.append(computeTFIDF(tf_idf_list))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Vectorizer_Yelp_Train = []\n",
    "iterator  = 0\n",
    "while iterator < len(New_TFIDF_Yelp_Train):\n",
    "    New_Vectorizer_Yelp_Train.append(list(New_TFIDF_Yelp_Train[iterator]))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=800,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Waktu_Training = time()\n",
    "New_RF_Classifier_Yelp = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "New_RF_Classifier_Yelp.fit(New_Vectorizer_Yelp_Train, Label_Yelp_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waktu prediksi (test): 176.545s\n",
      "Skor Random Forest Test Yelp : 0.8629333333333333\n",
      "waktu prediksi (test): 2.07s\n",
      "Skor Random Forest Test Yelp : 0.8376\n"
     ]
    }
   ],
   "source": [
    "Waktu_Predict_Train = time()\n",
    "New_Skor_Train_Yelp = New_RF_Classifier_Yelp.score(Vectorizer_Yelp_Train, Label_Yelp_Train)\n",
    "print(f\"waktu prediksi (test): {round(time()-Waktu_Predict_Test, 3)}s\")\n",
    "print(\"Skor Random Forest Test Yelp : {}\".format(New_Skor_Train_Yelp))\n",
    "\n",
    "Waktu_Predict_Test = time()\n",
    "New_Skor_Test_Yelp = New_RF_Classifier_Yelp.score(Vectorizer_Yelp_Test, Label_Yelp_Test)\n",
    "print(f\"waktu prediksi (test): {round(time()-Waktu_Predict_Test, 3)}s\")\n",
    "print(\"Skor Random Forest Test Yelp : {}\".format(New_Skor_Test_Yelp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
