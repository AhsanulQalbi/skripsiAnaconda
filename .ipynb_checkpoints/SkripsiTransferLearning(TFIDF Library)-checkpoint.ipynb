{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKRIPSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, validation_curve,RandomizedSearchCV\n",
    "\n",
    "np.random.seed(0)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "poster_Stemmer = nltk.PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baca file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baca csv\n",
    "data_amazon = pd.read_csv('Amazon_dataset.csv')\n",
    "data_yelp = pd.read_csv('Yelp_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen\n",
       "0      0  Buyer beware This is a self-published book, an...\n",
       "1      0  The Worst! A complete waste of time. Typograph...\n",
       "2      0  Oh please I guess you have to be a romance nov...\n",
       "3      0  Awful beyond belief! I feel I have to write to...\n",
       "4      0  Another Abysmal Digital Copy Rather than scrat..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen\n",
       "0      0  I don't know what Dr. Goldberg was like before...\n",
       "1      0  I'm writing this review to give you a heads up...\n",
       "2      0  Owning a driving range inside the city limits ...\n",
       "3      0  This place is absolute garbage...  Half of the...\n",
       "4      0  Used to go there for tires, brakes, etc.  Thei..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing ke lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_FaseToLowercase_Amazon = data_amazon\n",
    "data_Lowercase_Amazon = []\n",
    "\n",
    "data_FaseToLowercase_Yelp = data_yelp\n",
    "data_Lowercase_Yelp = []\n",
    "\n",
    "while iterator < len(data_amazon) :\n",
    "    data_Lowercase_Amazon.append(data_amazon.Sentimen[iterator].lower())\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_yelp) :\n",
    "    data_Lowercase_Yelp.append(data_yelp.Sentimen[iterator].lower())\n",
    "    iterator = iterator + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \n",
       "0  buyer beware this is a self-published book, an...  \n",
       "1  the worst! a complete waste of time. typograph...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief! i feel i have to write to...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_FaseToLowercase_Amazon['Lowercase'] = data_Lowercase_Amazon\n",
    "data_FaseToLowercase_Amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \n",
       "0  i don't know what dr. goldberg was like before...  \n",
       "1  i'm writing this review to give you a heads up...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage...  half of the...  \n",
       "4  used to go there for tires, brakes, etc.  thei...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_FaseToLowercase_Yelp['Lowercase'] = data_Lowercase_Yelp\n",
    "data_FaseToLowercase_Yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghilangkan angka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_FaseRemoveNumber_Amazon = data_FaseToLowercase_Amazon\n",
    "data_RemoveNumber_Amazon = []\n",
    "\n",
    "data_FaseRemoveNumber_Yelp = data_FaseToLowercase_Yelp\n",
    "data_RemoveNumber_Yelp = []\n",
    "\n",
    "while iterator < len(data_FaseToLowercase_Amazon) :\n",
    "    data_RemoveNumber_Amazon.append(re.sub(r\"\\d+\", \"\",data_FaseRemoveNumber_Amazon.Lowercase[iterator]))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_FaseToLowercase_Yelp) :\n",
    "    data_RemoveNumber_Yelp.append(re.sub(r\"\\d+\", \"\",data_FaseRemoveNumber_Yelp.Lowercase[iterator]))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                        RemoveNumber  \n",
       "0  buyer beware this is a self-published book, an...  \n",
       "1  the worst! a complete waste of time. typograph...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief! i feel i have to write to...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_FaseRemoveNumber_Amazon['RemoveNumber'] = data_RemoveNumber_Amazon\n",
    "data_FaseRemoveNumber_Amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                        RemoveNumber  \n",
       "0  i don't know what dr. goldberg was like before...  \n",
       "1  i'm writing this review to give you a heads up...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage...  half of the...  \n",
       "4  used to go there for tires, brakes, etc.  thei...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_FaseRemoveNumber_Yelp['RemoveNumber'] = data_RemoveNumber_Yelp\n",
    "data_FaseRemoveNumber_Yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghilangkan tanda baca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_FaseRemovePunctuation_Amazon = data_FaseRemoveNumber_Amazon\n",
    "data_RemovePunctuation_Amazon = []\n",
    "\n",
    "data_FaseRemovePunctuation_Yelp = data_FaseRemoveNumber_Yelp\n",
    "data_RemovePunctuation_Yelp = []\n",
    "\n",
    "while iterator < len(data_FaseRemoveNumber_Amazon) :\n",
    "    data_RemovePunctuation_Amazon.append(data_FaseRemovePunctuation_Amazon.RemoveNumber[iterator].translate(str.maketrans('','', string.punctuation)))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_FaseToLowercase_Yelp) :\n",
    "    data_RemovePunctuation_Yelp.append(data_FaseRemovePunctuation_Yelp.RemoveNumber[iterator].translate(str.maketrans('','', string.punctuation)))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a selfpublished book and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst a complete waste of time typographic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief i feel i have to write to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                   RemovePunctuation  \n",
       "0  buyer beware this is a selfpublished book and ...  \n",
       "1  the worst a complete waste of time typographic...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief i feel i have to write to ...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_FaseRemovePunctuation_Amazon['RemovePunctuation'] = data_RemovePunctuation_Amazon\n",
    "data_FaseRemovePunctuation_Amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i dont know what dr goldberg was like before  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>im writing this review to give you a heads up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage  half of the te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires brakes etc  their p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                   RemovePunctuation  \n",
       "0  i dont know what dr goldberg was like before  ...  \n",
       "1  im writing this review to give you a heads up ...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage  half of the te...  \n",
       "4  used to go there for tires brakes etc  their p...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_FaseRemovePunctuation_Yelp['RemovePunctuation'] = data_RemovePunctuation_Yelp\n",
    "data_FaseRemovePunctuation_Yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghilangkan Non alfabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_FaseRegex_alpabet_only_Amazon = data_FaseRemovePunctuation_Amazon\n",
    "data_Regex_alpabet_only_Amazon = []\n",
    "\n",
    "data_FaseRegex_alpabet_only_Yelp = data_FaseRemovePunctuation_Yelp\n",
    "data_Regex_alpabet_only_Yelp = []\n",
    "\n",
    "\n",
    "while iterator < len(data_FaseRemovePunctuation_Amazon) :\n",
    "    data_Regex_alpabet_only_Amazon.append(\" \".join(re.findall(\"[a-zA-Z]+\", data_FaseRegex_alpabet_only_Amazon.RemovePunctuation[iterator])))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_FaseRemovePunctuation_Amazon) :\n",
    "    data_Regex_alpabet_only_Yelp.append(\" \".join(re.findall(r\"[a-zA-Z]+\", data_FaseRegex_alpabet_only_Yelp.RemovePunctuation[iterator])))\n",
    "    iterator = iterator + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "      <th>Regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a selfpublished book and ...</td>\n",
       "      <td>buyer beware this is a selfpublished book and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst a complete waste of time typographic...</td>\n",
       "      <td>the worst a complete waste of time typographic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief i feel i have to write to ...</td>\n",
       "      <td>awful beyond belief i feel i have to write to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                   RemovePunctuation  \\\n",
       "0  buyer beware this is a selfpublished book and ...   \n",
       "1  the worst a complete waste of time typographic...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief i feel i have to write to ...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                               Regex  \n",
       "0  buyer beware this is a selfpublished book and ...  \n",
       "1  the worst a complete waste of time typographic...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief i feel i have to write to ...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_FaseRegex_alpabet_only_Amazon['Regex'] = data_Regex_alpabet_only_Amazon\n",
    "data_FaseRegex_alpabet_only_Amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "      <th>Regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i dont know what dr goldberg was like before  ...</td>\n",
       "      <td>i dont know what dr goldberg was like before m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>im writing this review to give you a heads up ...</td>\n",
       "      <td>im writing this review to give you a heads up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage  half of the te...</td>\n",
       "      <td>this place is absolute garbage half of the tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires brakes etc  their p...</td>\n",
       "      <td>used to go there for tires brakes etc their pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                   RemovePunctuation  \\\n",
       "0  i dont know what dr goldberg was like before  ...   \n",
       "1  im writing this review to give you a heads up ...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage  half of the te...   \n",
       "4  used to go there for tires brakes etc  their p...   \n",
       "\n",
       "                                               Regex  \n",
       "0  i dont know what dr goldberg was like before m...  \n",
       "1  im writing this review to give you a heads up ...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage half of the tee...  \n",
       "4  used to go there for tires brakes etc their pr...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_FaseRegex_alpabet_only_Yelp['Regex'] = data_Regex_alpabet_only_Yelp\n",
    "data_FaseRegex_alpabet_only_Yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorisasi data sentimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vectorizer_Amazon = TfidfVectorizer(ngram_range=(2,3), analyzer = 'char')\n",
    "vectorizer_Yelp = TfidfVectorizer(ngram_range=(2,3), analyzer = 'char')\n",
    "#ngram nya range 2,2 , 2,3, 3,3 \n",
    "#tfidf range\n",
    "#klo kolom data > 500 pakein PCA 500 atau gapake sambil hyperparameter randomforest\n",
    "#analyzer = 'char_wb, word'\n",
    "#cobain tfid (analyz) di 10000 data\n",
    "#cobain PCA\n",
    "Label_Amazon = data_FaseRegex_alpabet_only_Amazon.Label\n",
    "Clean_Amazon_Sentiment = data_Regex_alpabet_only_Amazon\n",
    "\n",
    "Label_Yelp = data_FaseRegex_alpabet_only_Yelp.Label\n",
    "Clean_Yelp_Sentiment = data_Regex_alpabet_only_Yelp\n",
    "\n",
    "Vectorizer_Amazon = vectorizer_Amazon.fit_transform(Clean_Amazon_Sentiment)\n",
    "Vocabulary_Amazon = vectorizer_Amazon.get_feature_names()\n",
    "\n",
    "Vectorizer_Yelp = vectorizer_Yelp.fit_transform(Clean_Yelp_Sentiment)\n",
    "Vocabulary_Yelp = vectorizer_Yelp.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Data Sentimen Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a    aa        ab        ac        ad   ae        af  \\\n",
      "0     0.174876  0.079683  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "1     0.149460  0.046820  0.0  0.044112  0.051802  0.056224  0.0  0.000000   \n",
      "2     0.122932  0.056014  0.0  0.026387  0.000000  0.000000  0.0  0.034222   \n",
      "3     0.107129  0.041304  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "4     0.121443  0.022826  0.0  0.014337  0.016837  0.000000  0.0  0.000000   \n",
      "...        ...       ...  ...       ...       ...       ...  ...       ...   \n",
      "9995  0.048360  0.015149  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "9996  0.051526  0.021522  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "9997  0.110433  0.046126  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "9998  0.033297  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "9999  0.089949  0.045084  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "\n",
      "           ag   ah  ...  zzf  zzi  zzk  zzl  zzo  zzs  zzt  zzu  zzy  zzz  \n",
      "0     0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.02428  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "9995  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "9996  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "9997  0.05423  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "9998  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "9999  0.00000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[10000 rows x 9905 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Amazon = pd.DataFrame(Vectorizer_Amazon.toarray(), columns = Vocabulary_Amazon)\n",
    "print (DataFrame_Amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Sentimen Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a    aa        ab        ac        ad   ae        af  \\\n",
      "0     0.171501  0.048055  0.0  0.036048  0.000000  0.017099  0.0  0.014372   \n",
      "1     0.140692  0.044075  0.0  0.012858  0.000000  0.036593  0.0  0.000000   \n",
      "2     0.159668  0.054783  0.0  0.011986  0.045752  0.017056  0.0  0.000000   \n",
      "3     0.190210  0.025380  0.0  0.022212  0.000000  0.000000  0.0  0.026567   \n",
      "4     0.059506  0.035729  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "...        ...       ...  ...       ...       ...       ...  ...       ...   \n",
      "9995  0.120945  0.016138  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "9996  0.090639  0.036282  0.0  0.000000  0.000000  0.090368  0.0  0.000000   \n",
      "9997  0.181633  0.019829  0.0  0.000000  0.000000  0.000000  0.0  0.041512   \n",
      "9998  0.169450  0.040697  0.0  0.011872  0.015106  0.000000  0.0  0.014200   \n",
      "9999  0.154483  0.037103  0.0  0.000000  0.041315  0.000000  0.0  0.000000   \n",
      "\n",
      "       ag        ah  ...  zzb  zzc  zze  zzi  zzl  zzn  zzo  zzu  zzy  zzz  \n",
      "0     0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "9995  0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "9996  0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "9997  0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "9998  0.0  0.027294  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "9999  0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[10000 rows x 9856 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Yelp = pd.DataFrame(Vectorizer_Yelp.toarray(), columns = Vocabulary_Yelp)\n",
    "print (DataFrame_Yelp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jumlah data label positif dan negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data positif negatif amazon\n",
      "1    5000\n",
      "0    5000\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "\n",
      "Data positif negatif yelp\n",
      "1    5000\n",
      "0    5000\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Data positif negatif amazon\")\n",
    "DataFrame_Label = pd.DataFrame(Label_Amazon)\n",
    "print(DataFrame_Label['Label'].value_counts())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Data positif negatif yelp\")\n",
    "DataFrame_Label = pd.DataFrame(Label_Yelp)\n",
    "print(DataFrame_Label['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split data amazon dan yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_amazon, data_test_amazon, label_train_amazon, label_test_amazon = train_test_split(Vectorizer_Amazon.toarray(), Label_Amazon, random_state = 0)\n",
    "data_train_yelp, data_test_yelp, label_train_yelp, label_test_yelp = train_test_split(Vectorizer_Yelp.toarray(), Label_Yelp, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon data\n",
      "data train shape : (7500, 9905)\n",
      "data test shape : (2500, 9905)\n",
      "label train shape : (7500,)\n",
      "label test shape : (2500,)\n",
      "\n",
      "Yelp data\n",
      "data train shape : (7500, 9856)\n",
      "data test shape : (2500, 9856)\n",
      "label train shape : (7500,)\n",
      "label test shape : (2500,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Amazon data\")\n",
    "print(\"data train shape : {}\".format(data_train_amazon.shape))\n",
    "print(\"data test shape : {}\".format(data_test_amazon.shape))\n",
    "print(\"label train shape : {}\".format(label_train_amazon.shape))\n",
    "print(\"label test shape : {}\".format(label_test_amazon.shape))\n",
    "\n",
    "print(\"\\nYelp data\")\n",
    "print(\"data train shape : {}\".format(data_train_yelp.shape))\n",
    "print(\"data test shape : {}\".format(data_test_yelp.shape))\n",
    "print(\"label train shape : {}\".format(label_train_yelp.shape))\n",
    "print(\"label test shape : {}\".format(label_test_yelp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# dr = PCA(n_components = 300)\n",
    "# dr.fit(data_train_amazon)\n",
    "# data_train_amazon = dr.transform(data_train_amazon)\n",
    "# data_test_amazon = dr.transform(data_test_amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skor Akurasi Amazon dan Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skor RF_Amazon: 0.8184\n",
      "skor RF_Yelp: 0.8256\n"
     ]
    }
   ],
   "source": [
    "RF_Classifier_Amazon = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Amazon.fit(data_train_amazon, label_train_amazon)\n",
    "print(\"skor RF_Amazon: {}\".format(RF_Classifier_Amazon.score(data_test_amazon, label_test_amazon)))\n",
    "\n",
    "RF_Classifier_Yelp = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Yelp.fit(data_train_yelp, label_train_yelp)\n",
    "print(\"skor RF_Yelp: {}\".format(RF_Classifier_Yelp.score(data_test_yelp, label_test_yelp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_Importance_Amazon = []\n",
    "iterator = 0\n",
    "length = len (Vocabulary_Amazon)\n",
    "\n",
    "while iterator < length : \n",
    "    if RF_Classifier_Amazon.feature_importances_[iterator] > 0 :\n",
    "        Vocabulary_Importance_Amazon.append(Vocabulary_Amazon[iterator])\n",
    "       \n",
    "    iterator = iterator + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat Vectorizer baru dari data fitur importance only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_importance_amazon = TfidfVectorizer(vocabulary = Vocabulary_Importance_Amazon, ngram_range=(2,3), analyzer = 'char_wb')\n",
    "Vocabulary_Importance_Amazon_Clean = vectorizer_importance_amazon.get_feature_names()\n",
    "Vectorizer_Importance_Amazon = vectorizer_importance_amazon.fit_transform(Clean_Amazon_Sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Amazon dengan fitur importance > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a         ab        ac        ad        af        ag  \\\n",
      "0     0.189565  0.085772  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1     0.162808  0.050645  0.047877  0.056451  0.061177  0.000000  0.000000   \n",
      "2     0.134657  0.060928  0.028799  0.000000  0.000000  0.037482  0.000000   \n",
      "3     0.121781  0.043294  0.000000  0.000000  0.000000  0.000000  0.025633   \n",
      "4     0.138753  0.024664  0.015544  0.018328  0.000000  0.000000  0.000000   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  0.051326  0.015966  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "9996  0.055924  0.023195  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "9997  0.124458  0.051620  0.000000  0.000000  0.000000  0.000000  0.061126   \n",
      "9998  0.058099  0.000000  0.045561  0.000000  0.000000  0.000000  0.000000   \n",
      "9999  0.118441  0.049124  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "       ai        al        am  ...  zer  zes        zi       zin  zit  \\\n",
      "0     0.0  0.000000  0.043515  ...  0.0  0.0  0.000000  0.000000  0.0   \n",
      "1     0.0  0.000000  0.000000  ...  0.0  0.0  0.000000  0.000000  0.0   \n",
      "2     0.0  0.064706  0.000000  ...  0.0  0.0  0.000000  0.000000  0.0   \n",
      "3     0.0  0.015326  0.000000  ...  0.0  0.0  0.000000  0.000000  0.0   \n",
      "4     0.0  0.000000  0.016684  ...  0.0  0.0  0.000000  0.000000  0.0   \n",
      "...   ...       ...       ...  ...  ...  ...       ...       ...  ...   \n",
      "9995  0.0  0.000000  0.000000  ...  0.0  0.0  0.000000  0.000000  0.0   \n",
      "9996  0.0  0.000000  0.000000  ...  0.0  0.0  0.000000  0.000000  0.0   \n",
      "9997  0.0  0.000000  0.000000  ...  0.0  0.0  0.000000  0.000000  0.0   \n",
      "9998  0.0  0.000000  0.000000  ...  0.0  0.0  0.000000  0.000000  0.0   \n",
      "9999  0.0  0.034780  0.049845  ...  0.0  0.0  0.076316  0.078728  0.0   \n",
      "\n",
      "            zo       zon   zs  zz   zzy  \n",
      "0     0.032139  0.033359  0.0  0.0  0.0  \n",
      "1     0.000000  0.000000  0.0  0.0  0.0  \n",
      "2     0.000000  0.000000  0.0  0.0  0.0  \n",
      "3     0.000000  0.000000  0.0  0.0  0.0  \n",
      "4     0.024645  0.025580  0.0  0.0  0.0  \n",
      "...        ...       ...  ...  ...  ...  \n",
      "9995  0.000000  0.000000  0.0  0.0  0.0  \n",
      "9996  0.000000  0.000000  0.0  0.0  0.0  \n",
      "9997  0.000000  0.000000  0.0  0.0  0.0  \n",
      "9998  0.000000  0.000000  0.0  0.0  0.0  \n",
      "9999  0.000000  0.000000  0.0  0.0  0.0  \n",
      "\n",
      "[10000 rows x 2903 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Importance_Amazon = pd.DataFrame(Vectorizer_Importance_Amazon.toarray(), columns = Vocabulary_Importance_Amazon_Clean)\n",
    "print (DataFrame_Importance_Amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_importance_amazon, data_test_importance_amazon, label_train_importance_amazon, label_test_importance_amazon = train_test_split(Vectorizer_Importance_Amazon.toarray(), Label_Amazon, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Importance data\n",
      "data train shape : (7500, 2903)\n",
      "data test shape : (2500, 2903)\n",
      "label train shape : (7500,)\n",
      "label test shape : (2500,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Amazon Importance data\")\n",
    "print(\"data train shape : {}\".format(data_train_importance_amazon.shape))\n",
    "print(\"data test shape : {}\".format(data_test_importance_amazon.shape))\n",
    "print(\"label train shape : {}\".format(label_train_importance_amazon.shape))\n",
    "print(\"label test shape : {}\".format(label_test_importance_amazon.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Akurasi Amazon dengan fitur importance > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skor RF_Amazon: 0.81\n"
     ]
    }
   ],
   "source": [
    "RF_Classifier_Amazon_Importance = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Amazon_Importance.fit(data_train_importance_amazon, label_train_importance_amazon)\n",
    "print(\"skor RF_Amazon: {}\".format(RF_Classifier_Amazon_Importance.score(data_test_importance_amazon, label_test_importance_amazon)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengetahui akurasi dari interseksi data yelp dan amazon(FI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_intersection = list(set(Vocabulary_Importance_Amazon) & set (Vocabulary_Yelp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2898\n"
     ]
    }
   ],
   "source": [
    "print(len(Vocabulary_intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_intersection_yelp = TfidfVectorizer(vocabulary = Vocabulary_intersection, ngram_range=(2,3), analyzer = 'char_wb')\n",
    "Vocabulary_Intersection = vectorizer_intersection_yelp.get_feature_names()\n",
    "Vectorizer_Intersection_Yelp = vectorizer_intersection_yelp.fit_transform(Clean_Yelp_Sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe interseksi yelp dan amazon (FI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ee       tak  hri       ret  k p  n h  eng  aul       him  h m  \\\n",
      "0     0.008210  0.000000  0.0  0.016903  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
      "1     0.008646  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.023218  0.0   \n",
      "2     0.032267  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
      "3     0.044303  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
      "4     0.021792  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
      "...        ...       ...  ...       ...  ...  ...  ...  ...       ...  ...   \n",
      "9995  0.038915  0.000000  0.0  0.080118  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
      "9996  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
      "9997  0.023417  0.046101  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
      "9998  0.031959  0.000000  0.0  0.016449  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
      "9999  0.044492  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
      "\n",
      "      ...  ply  k m   sk       adu  k c  oft        ot  obt        th  \\\n",
      "0     ...  0.0  0.0  0.0  0.034474  0.0  0.0  0.000000  0.0  0.142899   \n",
      "1     ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  0.111230   \n",
      "2     ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  0.207551   \n",
      "3     ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  0.145279   \n",
      "4     ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  0.148421   \n",
      "...   ...  ...  ...  ...       ...  ...  ...       ...  ...       ...   \n",
      "9995  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  0.161967   \n",
      "9996  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  0.104046   \n",
      "9997  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  0.159484   \n",
      "9998  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  0.126969   \n",
      "9999  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.044407  0.0  0.101008   \n",
      "\n",
      "            ye  \n",
      "0     0.000000  \n",
      "1     0.000000  \n",
      "2     0.037109  \n",
      "3     0.000000  \n",
      "4     0.000000  \n",
      "...        ...  \n",
      "9995  0.000000  \n",
      "9996  0.000000  \n",
      "9997  0.000000  \n",
      "9998  0.000000  \n",
      "9999  0.000000  \n",
      "\n",
      "[10000 rows x 2898 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Intersection = pd.DataFrame(Vectorizer_Intersection_Yelp.toarray(), columns = Vocabulary_Intersection)\n",
    "print (DataFrame_Intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_intersection, data_test_intersection, label_train_intersection, label_test_intersection = train_test_split(Vectorizer_Intersection_Yelp.toarray(), Label_Yelp, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection data\n",
      "data train shape : (7500, 2898)\n",
      "data test shape : (2500, 2898)\n",
      "label train shape : (7500,)\n",
      "label test shape : (2500,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Intersection data\")\n",
    "print(\"data train shape : {}\".format(data_train_intersection.shape))\n",
    "print(\"data test shape : {}\".format(data_test_intersection.shape))\n",
    "print(\"label train shape : {}\".format(label_train_intersection.shape))\n",
    "print(\"label test shape : {}\".format(label_test_intersection.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Akurasi interseksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skor RF_Interseksi: 0.8348\n"
     ]
    }
   ],
   "source": [
    "RF_Classifier_Yelp_intersec = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Yelp_intersec.fit(data_train_intersection, label_train_intersection)\n",
    "print(\"skor RF_Interseksi: {}\".format(RF_Classifier_Yelp_intersec.score(data_test_intersection, label_test_intersection)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengetahui akurasi dari gabungan data yelp dan amazon(FI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_Gabungan_Yelp = []\n",
    "iterator = 0\n",
    "length = len(Vocabulary_Yelp)\n",
    "\n",
    "while iterator < length : \n",
    "#     jika interseksi dengan amazon dan bukan fitur importance maka vocab tidak dimasukan\n",
    "    if  (Vocabulary_Yelp[iterator] in Vocabulary_Amazon) and (Vocabulary_Yelp[iterator] not in Vocabulary_Importance_Amazon) : \n",
    "        iterator = iterator + 1\n",
    "        continue\n",
    "        \n",
    "    Vocabulary_Gabungan_Yelp.append(Vocabulary_Yelp[iterator])\n",
    "    iterator = iterator + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4291\n"
     ]
    }
   ],
   "source": [
    "print(len(Vocabulary_Gabungan_Yelp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_gabungan_yelp = TfidfVectorizer(vocabulary = Vocabulary_Gabungan_Yelp, ngram_range=(2,3), analyzer = 'char_wb')\n",
    "Vocabulary_Gabungan_Yelp = vectorizer_gabungan_yelp.get_feature_names()\n",
    "Vectorizer_Gabungan_Yelp = vectorizer_gabungan_yelp.fit_transform(Clean_Yelp_Sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Gabungan Yelp dengan Amazon(FI>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a         ab        ac        ad        af   ag   ai  \\\n",
      "0     0.185348  0.051917  0.038885  0.000000  0.018503  0.015456  0.0  0.0   \n",
      "1     0.149646  0.046863  0.013650  0.000000  0.038971  0.000000  0.0  0.0   \n",
      "2     0.169910  0.058276  0.012731  0.048764  0.018174  0.000000  0.0  0.0   \n",
      "3     0.200032  0.026681  0.023314  0.000000  0.000000  0.027800  0.0  0.0   \n",
      "4     0.065596  0.039372  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "...        ...       ...       ...       ...       ...       ...  ...  ...   \n",
      "9995  0.131778  0.017577  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "9996  0.103465  0.041401  0.000000  0.000000  0.103288  0.000000  0.0  0.0   \n",
      "9997  0.193836  0.021153  0.000000  0.000000  0.000000  0.044082  0.0  0.0   \n",
      "9998  0.180169  0.043256  0.012600  0.016087  0.000000  0.015024  0.0  0.0   \n",
      "9999  0.167406  0.040192  0.000000  0.044842  0.000000  0.000000  0.0  0.0   \n",
      "\n",
      "            al        am  ...  zxl  zyb  zye  zyl  zyn  zyy  zz   zzc  zzn  \\\n",
      "0     0.010044  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1     0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2     0.019730  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3     0.036131  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4     0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...        ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "9995  0.023803  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9996  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9997  0.028646  0.082674  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9998  0.009763  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9999  0.027214  0.039271  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      zzy  \n",
      "0     0.0  \n",
      "1     0.0  \n",
      "2     0.0  \n",
      "3     0.0  \n",
      "4     0.0  \n",
      "...   ...  \n",
      "9995  0.0  \n",
      "9996  0.0  \n",
      "9997  0.0  \n",
      "9998  0.0  \n",
      "9999  0.0  \n",
      "\n",
      "[10000 rows x 4291 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Gabungan = pd.DataFrame(Vectorizer_Gabungan_Yelp.toarray(), columns = Vocabulary_Gabungan_Yelp)\n",
    "print (DataFrame_Gabungan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_gab_yelp, data_test_gab_yelp, label_train_gab_yelp, label_test_gab_yelp = train_test_split(Vectorizer_Gabungan_Yelp.toarray(), Label_Yelp, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp data Gabungan\n",
      "data train shape : (7500, 4291)\n",
      "data test shape : (2500, 4291)\n",
      "label train shape : (7500,)\n",
      "label test shape : (2500,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Yelp data Gabungan\")\n",
    "print(\"data train shape : {}\".format(data_train_gab_yelp.shape))\n",
    "print(\"data test shape : {}\".format(data_test_gab_yelp.shape))\n",
    "print(\"label train shape : {}\".format(label_train_gab_yelp.shape))\n",
    "print(\"label test shape : {}\".format(label_test_gab_yelp.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Akurasi gabungan yelp dan amazon (Fi>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skor Gabungan: 0.8284\n"
     ]
    }
   ],
   "source": [
    "RF_Classifier_Yelp_gabungan = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Yelp_gabungan.fit(data_train_gab_yelp, label_train_gab_yelp)\n",
    "print(\"skor Gabungan: {}\".format(RF_Classifier_Yelp_gabungan.score(data_test_gab_yelp, label_test_gab_yelp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5145)\t0.02161583914498161\n",
      "  (0, 6227)\t0.018774747928181835\n",
      "  (0, 7214)\t0.019140326403469247\n",
      "  (0, 2991)\t0.01976749667096081\n",
      "  (0, 1051)\t0.030392099739082093\n",
      "  (0, 24)\t0.026554689961178175\n",
      "  (0, 6919)\t0.015738501247955894\n",
      "  (0, 6924)\t0.02343192974611269\n",
      "  (0, 2811)\t0.06239354566120495\n",
      "  (0, 9414)\t0.04029953406993937\n",
      "  (0, 7879)\t0.036741269370477586\n",
      "  (0, 4473)\t0.026606003172040787\n",
      "  (0, 6183)\t0.02989379203016984\n",
      "  (0, 4336)\t0.04272716366261396\n",
      "  (0, 241)\t0.02802211462195735\n",
      "  (0, 598)\t0.03939250713810272\n",
      "  (0, 964)\t0.011345512069703313\n",
      "  (0, 20)\t0.016850352781044048\n",
      "  (0, 2544)\t0.033956610528652086\n",
      "  (0, 5242)\t0.03447736122606571\n",
      "  (0, 4401)\t0.021326091969544103\n",
      "  (0, 7501)\t0.025707135053855\n",
      "  (0, 1853)\t0.010812458756681473\n",
      "  (0, 6048)\t0.019621770300588953\n",
      "  (0, 6281)\t0.01973884881780262\n",
      "  :\t:\n",
      "  (9999, 5963)\t0.06006984046748991\n",
      "  (9999, 8070)\t0.06205515255739138\n",
      "  (9999, 7828)\t0.12565201345567603\n",
      "  (9999, 524)\t0.07557582968694111\n",
      "  (9999, 6399)\t0.020547383214912302\n",
      "  (9999, 5587)\t0.019461361111353728\n",
      "  (9999, 868)\t0.03729538615533572\n",
      "  (9999, 1319)\t0.02695640300285303\n",
      "  (9999, 1833)\t0.03617446376357137\n",
      "  (9999, 3476)\t0.07409219821116385\n",
      "  (9999, 429)\t0.03788269039447188\n",
      "  (9999, 588)\t0.04329329294027189\n",
      "  (9999, 0)\t0.08994910423156294\n",
      "  (9999, 200)\t0.07242856233927257\n",
      "  (9999, 7386)\t0.10711102890099998\n",
      "  (9999, 4098)\t0.0756136994417036\n",
      "  (9999, 3527)\t0.039142301402048406\n",
      "  (9999, 7971)\t0.12523806706919044\n",
      "  (9999, 456)\t0.16034555969675848\n",
      "  (9999, 2216)\t0.03560741502784444\n",
      "  (9999, 7028)\t0.037700944262861885\n",
      "  (9999, 8940)\t0.04962664764092816\n",
      "  (9999, 28)\t0.01914752687958993\n",
      "  (9999, 6918)\t0.07745562121928326\n",
      "  (9999, 2577)\t0.07486761239589322\n"
     ]
    }
   ],
   "source": [
    "print(Vectorizer_Amazon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
