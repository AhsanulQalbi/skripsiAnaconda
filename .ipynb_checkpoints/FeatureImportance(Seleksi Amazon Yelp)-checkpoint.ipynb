{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKRIPSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "from nltk import ngrams\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, validation_curve,RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from matplotlib_venn import venn2\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from joblib import dump, load\n",
    "np.random.seed(0)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "poster_Stemmer = nltk.PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baca file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_yelp = pd.read_csv('dataset/Yelp_Train.csv')\n",
    "data_test_yelp = pd.read_csv('dataset/Yelp_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label                                           Sentimen\n",
      "0      0  I don't know what Dr. Goldberg was like before...\n",
      "1      0  I'm writing this review to give you a heads up...\n",
      "2      0  Owning a driving range inside the city limits ...\n",
      "3      0  This place is absolute garbage...  Half of the...\n",
      "4      0  Used to go there for tires, brakes, etc.  Thei...\n"
     ]
    }
   ],
   "source": [
    "print(data_train_yelp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label                                           Sentimen\n",
      "0      0  My wife and I used to love Arriba's, til recen...\n",
      "1      0  You get what you pay for.  The food is inexpen...\n",
      "2      0  Unfortunately, yesterday's visit was one of th...\n",
      "3      0  I went into the Scottsdale location yesterday....\n",
      "4      0  It takes a lot for me to write a review and bl...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data_test_yelp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_Preprocessing_Yelp_Train = data_train_yelp.Sentimen.astype(str)\n",
    "data_Preprocessing_Yelp_Train = data_Preprocessing_Yelp_Train.apply(lambda x: x.lower())\n",
    "data_Preprocessing_Yelp_Train = data_Preprocessing_Yelp_Train.apply(lambda x: re.sub(r\"\\d\", \"\", x))   \n",
    "data_Preprocessing_Yelp_Train = data_Preprocessing_Yelp_Train.apply(\n",
    "                                    lambda x: x.translate(str.maketrans('','',string.punctuation)))  \n",
    "data_Preprocessing_Yelp_Train = data_Preprocessing_Yelp_Train.apply(\n",
    "                                    lambda x: \" \".join(re.findall(\"[a-zA-Z]+\", x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i dont know what dr goldberg was like before m...\n",
       "1    im writing this review to give you a heads up ...\n",
       "2    owning a driving range inside the city limits ...\n",
       "3    this place is absolute garbage half of the tee...\n",
       "4    used to go there for tires brakes etc their pr...\n",
       "Name: Sentimen, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Preprocessing_Yelp_Test = data_test_yelp.Sentimen.astype(str)\n",
    "data_Preprocessing_Yelp_Test = data_Preprocessing_Yelp_Test.apply(lambda x: x.lower())\n",
    "data_Preprocessing_Yelp_Test = data_Preprocessing_Yelp_Test.apply(lambda x: re.sub(r\"\\d\", \"\", x))   \n",
    "data_Preprocessing_Yelp_Test = data_Preprocessing_Yelp_Test.apply(lambda x: x.translate(\n",
    "                                str.maketrans('','',string.punctuation)))  \n",
    "data_Preprocessing_Yelp_Test = data_Preprocessing_Yelp_Test.apply(lambda x: \" \".join(\n",
    "                                re.findall(\"[a-zA-Z]+\", x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    my wife and i used to love arribas til recentl...\n",
       "1    you get what you pay for the food is inexpensi...\n",
       "2    unfortunately yesterdays visit was one of the ...\n",
       "3    i went into the scottsdale location yesterday ...\n",
       "4    it takes a lot for me to write a review and bl...\n",
       "Name: Sentimen, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Clean_Yelp_Sentiment_Train = data_Preprocessing_Yelp_Train\n",
    "\n",
    "Label_Yelp_Train = data_train_yelp['Label']\n",
    "\n",
    "\n",
    "\n",
    "Clean_Yelp_Sentiment_Test = data_Preprocessing_Yelp_Test\n",
    "\n",
    "Label_Yelp_Test = data_test_yelp['Label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram (bigram dan trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_trigram(Clean_Sentiment) :\n",
    "    iterator = 0\n",
    "    Vocabulary = []\n",
    "    ngram_result = []\n",
    "    while iterator < len(Clean_Sentiment) :\n",
    "        ngram = 2\n",
    "        sentence = Clean_Sentiment[iterator]\n",
    "        vocab = list(ngrams(sentence, ngram))\n",
    "        temp = vocab\n",
    "\n",
    "        iterator2 = 0\n",
    "        while iterator2 < len (vocab):\n",
    "            if(vocab[iterator2] not in Vocabulary) :\n",
    "                Vocabulary.append(vocab[iterator2])\n",
    "            iterator2 = iterator2 + 1\n",
    "\n",
    "        ngram = 3\n",
    "        vocab = list(ngrams(sentence, ngram))\n",
    "        temp = temp + vocab\n",
    "        ngram_result.append(temp)\n",
    "        iterator2 = 0\n",
    "        while iterator2 < len (vocab):\n",
    "            if(vocab[iterator2] not in Vocabulary) :\n",
    "                Vocabulary.append(vocab[iterator2])\n",
    "            iterator2 = iterator2 + 1\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    return ngram_result,Vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_yelp_train, Vocabulary_Yelp_Train = bigram_trigram(Clean_Yelp_Sentiment_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_yelp_test, Vocabulary_Yelp_Test = bigram_trigram(Clean_Yelp_Sentiment_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionaryInitialize(Clean_Sentiment, Vocabulary, ngram, jenisdata) :\n",
    "    wordDictionaryCount = []\n",
    "    iterator = 0\n",
    "    while iterator < len(Clean_Sentiment):\n",
    "        wordDictionaryCount.append(dict.fromkeys(Vocabulary , 0))\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    iterator = 0\n",
    "    \n",
    "    while iterator < len(Clean_Sentiment) :\n",
    "        for gram in ngram[iterator] :\n",
    "            if (jenisdata == 'test' or jenisdata == 'transfer') and gram not in Vocabulary :\n",
    "                continue\n",
    "            wordDictionaryCount[iterator][gram] += 1\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    return wordDictionaryCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordDictionaryCount_Yelp_Train = dictionaryInitialize(Clean_Yelp_Sentiment_Train, Vocabulary_Yelp_Train, ngram_yelp_train,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordDictionaryCount_Yelp_Test = dictionaryInitialize(Clean_Yelp_Sentiment_Test, Vocabulary_Yelp_Train, ngram_yelp_test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(i,  )</th>\n",
       "      <th>( , d)</th>\n",
       "      <th>(d, o)</th>\n",
       "      <th>(o, n)</th>\n",
       "      <th>(n, t)</th>\n",
       "      <th>(t,  )</th>\n",
       "      <th>( , k)</th>\n",
       "      <th>(k, n)</th>\n",
       "      <th>(n, o)</th>\n",
       "      <th>(o, w)</th>\n",
       "      <th>...</th>\n",
       "      <th>(w, m, o)</th>\n",
       "      <th>(i, n, x)</th>\n",
       "      <th>(d, s, z)</th>\n",
       "      <th>(s, z, i)</th>\n",
       "      <th>(r, f, f)</th>\n",
       "      <th>(n, w,  )</th>\n",
       "      <th>(s, n, q)</th>\n",
       "      <th>(u, b, g)</th>\n",
       "      <th>(b, g, u)</th>\n",
       "      <th>(y, c, r)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 8197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (i,  )  ( , d)  (d, o)  (o, n)  (n, t)  (t,  )  ( , k)  (k, n)  (n, o)  \\\n",
       "0       4      11       6      13       7      19       1       1       5   \n",
       "1      10       7       6      10      13      21       1       1       1   \n",
       "\n",
       "   (o, w)  ...  (w, m, o)  (i, n, x)  (d, s, z)  (s, z, i)  (r, f, f)  \\\n",
       "0       1  ...          0          0          0          0          0   \n",
       "1       1  ...          0          0          0          0          0   \n",
       "\n",
       "   (n, w,  )  (s, n, q)  (u, b, g)  (b, g, u)  (y, c, r)  \n",
       "0          0          0          0          0          0  \n",
       "1          0          0          0          0          0  \n",
       "\n",
       "[2 rows x 8197 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([WordDictionaryCount_Yelp_Train[0],WordDictionaryCount_Yelp_Train[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung nilai TF pada setiap data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFrequency(wordDict, ngram):\n",
    "    freqword = {}\n",
    "    ngramLength = len(ngram)\n",
    "    for word, count in wordDict.items():\n",
    "        freqword[word] = count\n",
    "    return freqword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrequencyTermPerData(wordDictionary, ngram) :\n",
    "    CountFrequency = []\n",
    "    iterator = 0\n",
    "    while iterator < len(ngram):\n",
    "        CountFrequency.append(computeFrequency(wordDictionary[iterator], ngram[iterator]))\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    return CountFrequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountFrequency_Sentimen_Yelp_Train = getFrequencyTermPerData(WordDictionaryCount_Yelp_Train, ngram_yelp_train)\n",
    "CountFrequency_Sentimen_Yelp_Test = getFrequencyTermPerData(WordDictionaryCount_Yelp_Test, ngram_yelp_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung nilai IDF pada setiap data Amazon dan Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(WordDict):\n",
    "    idfDict = {}\n",
    "    number_of_document_with_term_t_in_it = {}\n",
    "    N = len(WordDict)\n",
    "    \n",
    "    idfDict = dict.fromkeys(WordDict[0].keys(), 0)\n",
    "    for doc in WordDict:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        number_of_document_with_term_t_in_it[word] = float(val)\n",
    "        idfDict[word] = np.log((1+N) / (1+val)) + 1\n",
    "        \n",
    "    return idfDict, number_of_document_with_term_t_in_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF_Yelp, number_of_document_with_term_t_in_Yelp_Train = computeIDF(WordDictionaryCount_Yelp_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDFnonScale(CountFrequency, idfs):\n",
    "    tfidf = None\n",
    "    tfidf = {}\n",
    "    for word, val in CountFrequency.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfidf_nonscaled) :\n",
    "    tfidf_nonscaled = np.array(tfidf_nonscaled)\n",
    "    tfidf_list = tfidf_nonscaled/sum(tfidf_nonscaled**2)**0.5\n",
    "    return tfidf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFIDF(wordDictionary, CountFrequency, IDF):\n",
    "    TFIDF_non_scaled = None\n",
    "    TFIDF_non_scaled = []\n",
    "    iterator = 0\n",
    "    while iterator < len(wordDictionary):\n",
    "        TFIDF_non_scaled.append(computeTFIDFnonScale(CountFrequency[iterator], IDF))\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    TFIDF = []\n",
    "    iterator = 0\n",
    "    while iterator < len(wordDictionary):\n",
    "        tf_idf_list = list(TFIDF_non_scaled[iterator].values())\n",
    "        TFIDF.append(computeTFIDF(tf_idf_list))\n",
    "        iterator = iterator + 1\n",
    "        \n",
    "    return TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_Yelp_Train = getTFIDF(WordDictionaryCount_Yelp_Train, CountFrequency_Sentimen_Yelp_Train, IDF_Yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_Yelp_Test = getTFIDF(WordDictionaryCount_Yelp_Test, CountFrequency_Sentimen_Yelp_Test, IDF_Yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toVectorizeList(TFIDF):\n",
    "    iterator  = 0\n",
    "    Vectorized = []\n",
    "    while iterator < len(TFIDF):\n",
    "        Vectorized.append(list(TFIDF[iterator]))\n",
    "        iterator = iterator + 1\n",
    "    return Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer_Yelp_Train = toVectorizeList(TFIDF_Yelp_Train)\n",
    "Vectorizer_Yelp_Test = toVectorizeList(TFIDF_Yelp_Test)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_Yelp_Train = Vectorizer_Yelp_Train\n",
    "TFIDF_Yelp_Test = Vectorizer_Yelp_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ( , a)  ( , a,  )  ( , a, a)  ( , a, b)  ( , a, c)  ( , a, d)  \\\n",
      "0     0.171153   0.047851        0.0   0.035851   0.000000   0.017313   \n",
      "1     0.140159   0.043810        0.0   0.012765   0.000000   0.036986   \n",
      "2     0.159834   0.054718        0.0   0.011957   0.045784   0.017323   \n",
      "3     0.190176   0.025319        0.0   0.022131   0.000000   0.000000   \n",
      "4     0.059505   0.035650        0.0   0.000000   0.000000   0.000000   \n",
      "...        ...        ...        ...        ...        ...        ...   \n",
      "3745  0.096302   0.020980        0.0   0.000000   0.000000   0.000000   \n",
      "3746  0.100676   0.015079        0.0   0.000000   0.000000   0.000000   \n",
      "3747  0.080185   0.000000        0.0   0.033592   0.000000   0.000000   \n",
      "3748  0.147717   0.023086        0.0   0.000000   0.000000   0.000000   \n",
      "3749  0.143471   0.053721        0.0   0.000000   0.000000   0.000000   \n",
      "\n",
      "      ( , a, e)  ( , a, f)  ( , a, g)  ( , a, h)  ...  (z, z,  )  (z, z, a)  \\\n",
      "0           0.0   0.014340    0.00000        0.0  ...        0.0        0.0   \n",
      "1           0.0   0.000000    0.00000        0.0  ...        0.0        0.0   \n",
      "2           0.0   0.000000    0.00000        0.0  ...        0.0        0.0   \n",
      "3           0.0   0.026556    0.00000        0.0  ...        0.0        0.0   \n",
      "4           0.0   0.000000    0.00000        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "3745        0.0   0.000000    0.00000        0.0  ...        0.0        0.0   \n",
      "3746        0.0   0.031631    0.00000        0.0  ...        0.0        0.0   \n",
      "3747        0.0   0.000000    0.00000        0.0  ...        0.0        0.0   \n",
      "3748        0.0   0.000000    0.01668        0.0  ...        0.0        0.0   \n",
      "3749        0.0   0.000000    0.00000        0.0  ...        0.0        0.0   \n",
      "\n",
      "      (z, z, b)  (z, z, c)  (z, z, e)  (z, z, i)  (z, z, l)  (z, z, o)  \\\n",
      "0           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "3745        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3746        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3747        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3748        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3749        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "      (z, z, y)  (z, z, z)  \n",
      "0           0.0        0.0  \n",
      "1           0.0        0.0  \n",
      "2           0.0        0.0  \n",
      "3           0.0        0.0  \n",
      "4           0.0        0.0  \n",
      "...         ...        ...  \n",
      "3745        0.0        0.0  \n",
      "3746        0.0        0.0  \n",
      "3747        0.0        0.0  \n",
      "3748        0.0        0.0  \n",
      "3749        0.0        0.0  \n",
      "\n",
      "[3750 rows x 8197 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Yelp_Train = pd.DataFrame(Vectorizer_Yelp_Train, columns = Vocabulary_Yelp_Train)\n",
    "DataFrame_Yelp_Train = DataFrame_Yelp_Train.reindex(sorted(DataFrame_Yelp_Train.columns), axis=1)\n",
    "print (DataFrame_Yelp_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ( , a)  ( , a,  )  ( , a, a)  ( , a, b)  ( , a, c)  ( , a, d)  \\\n",
      "0     0.164639   0.026303        0.0   0.022991        0.0   0.000000   \n",
      "1     0.078701   0.000000        0.0   0.000000        0.0   0.000000   \n",
      "2     0.089317   0.045865        0.0   0.000000        0.0   0.000000   \n",
      "3     0.120057   0.009590        0.0   0.000000        0.0   0.000000   \n",
      "4     0.164111   0.023980        0.0   0.000000        0.0   0.000000   \n",
      "...        ...        ...        ...        ...        ...        ...   \n",
      "1245  0.140150   0.083964        0.0   0.000000        0.0   0.035443   \n",
      "1246  0.073760   0.058919        0.0   0.000000        0.0   0.000000   \n",
      "1247  0.150321   0.045029        0.0   0.026239        0.0   0.000000   \n",
      "1248  0.021459   0.025712        0.0   0.000000        0.0   0.000000   \n",
      "1249  0.141502   0.036331        0.0   0.000000        0.0   0.000000   \n",
      "\n",
      "      ( , a, e)  ( , a, f)  ( , a, g)  ( , a, h)  ...  (z, z,  )  (z, z, a)  \\\n",
      "0           0.0   0.013794   0.000000        0.0  ...        0.0        0.0   \n",
      "1           0.0   0.000000   0.000000        0.0  ...        0.0        0.0   \n",
      "2           0.0   0.000000   0.000000        0.0  ...        0.0        0.0   \n",
      "3           0.0   0.020117   0.000000        0.0  ...        0.0        0.0   \n",
      "4           0.0   0.010061   0.031186        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1245        0.0   0.000000   0.030332        0.0  ...        0.0        0.0   \n",
      "1246        0.0   0.000000   0.000000        0.0  ...        0.0        0.0   \n",
      "1247        0.0   0.000000   0.000000        0.0  ...        0.0        0.0   \n",
      "1248        0.0   0.000000   0.000000        0.0  ...        0.0        0.0   \n",
      "1249        0.0   0.000000   0.026250        0.0  ...        0.0        0.0   \n",
      "\n",
      "      (z, z, b)  (z, z, c)  (z, z, e)  (z, z, i)  (z, z, l)  (z, z, o)  \\\n",
      "0           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1245        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1246        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1247        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1248        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1249        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "      (z, z, y)  (z, z, z)  \n",
      "0           0.0        0.0  \n",
      "1           0.0        0.0  \n",
      "2           0.0        0.0  \n",
      "3           0.0        0.0  \n",
      "4           0.0        0.0  \n",
      "...         ...        ...  \n",
      "1245        0.0        0.0  \n",
      "1246        0.0        0.0  \n",
      "1247        0.0        0.0  \n",
      "1248        0.0        0.0  \n",
      "1249        0.0        0.0  \n",
      "\n",
      "[1250 rows x 8197 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Yelp_Test = pd.DataFrame(Vectorizer_Yelp_Test, columns = Vocabulary_Yelp_Train)\n",
    "DataFrame_Yelp_Test = DataFrame_Yelp_Test.reindex(sorted(DataFrame_Yelp_Test.columns), axis=1)\n",
    "print (DataFrame_Yelp_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Akurasi dan Waktu Train Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waktu Training Yelp: 26.196s\n"
     ]
    }
   ],
   "source": [
    "Waktu_Training = time()\n",
    "RF_Classifier_Yelp = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Yelp.fit(Vectorizer_Yelp_Train, Label_Yelp_Train)\n",
    "print(f\"\\nWaktu Training Yelp: {round(time()-Waktu_Training, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waktu prediksi (train): 2.535s\n",
      "waktu prediksi (test): 0.944s\n",
      "\n",
      "Skor Random Forest Train Yelp : 0.9048\n",
      "Skor Random Forest Test Yelp : 0.8624\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[1653  222]\n",
      " [ 135 1740]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90      1875\n",
      "           1       0.89      0.93      0.91      1875\n",
      "\n",
      "    accuracy                           0.90      3750\n",
      "   macro avg       0.91      0.90      0.90      3750\n",
      "weighted avg       0.91      0.90      0.90      3750\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[539  86]\n",
      " [ 86 539]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       625\n",
      "           1       0.86      0.86      0.86       625\n",
      "\n",
      "    accuracy                           0.86      1250\n",
      "   macro avg       0.86      0.86      0.86      1250\n",
      "weighted avg       0.86      0.86      0.86      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Waktu_Predict_Train = time()\n",
    "Skor_Train_Yelp = RF_Classifier_Yelp.score(TFIDF_Yelp_Train, Label_Yelp_Train)\n",
    "print(f\"waktu prediksi (train): {round(time()-Waktu_Predict_Train, 3)}s\")\n",
    "\n",
    "Waktu_Predict_Test = time()\n",
    "Skor_Test_Yelp = RF_Classifier_Yelp.score(TFIDF_Yelp_Test, Label_Yelp_Test)\n",
    "print(f\"waktu prediksi (test): {round(time()-Waktu_Predict_Test, 3)}s\")\n",
    "\n",
    "print(\"\\nSkor Random Forest Train Yelp : {}\".format(Skor_Train_Yelp))\n",
    "print(\"Skor Random Forest Test Yelp : {}\".format(Skor_Test_Yelp))\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Yelp.predict(TFIDF_Yelp_Train)\n",
    "Confusion_matrix = confusion_matrix(Label_Yelp_Train, RFC_predict)\n",
    "print(\"\\n\\n\")\n",
    "print(Confusion_matrix)\n",
    "print(metrics.classification_report(Label_Yelp_Train, RFC_predict))\n",
    "\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Yelp.predict(TFIDF_Yelp_Test)\n",
    "Confusion_matrix = confusion_matrix(Label_Yelp_Test, RFC_predict)\n",
    "print(Confusion_matrix)\n",
    "print(metrics.classification_report(Label_Yelp_Test, RFC_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_Amazon_Train = load('savedlist/VocabularyTrainAmazon.pkl')\n",
    "Vocabulary_Importance_Amazon_Train = load('savedlist/vocabularyImportanceAmazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_Seleksi_Yelp = []\n",
    "iterator = 0\n",
    "length = len(Vocabulary_Yelp_Train)\n",
    "\n",
    "while iterator < length : \n",
    "#     jika interseksi dengan amazon dan bukan fitur importance maka vocab tidak dimasukan\n",
    "    if  (Vocabulary_Yelp_Train[iterator] in Vocabulary_Amazon_Train) and (\n",
    "            Vocabulary_Yelp_Train[iterator] not in Vocabulary_Importance_Amazon_Train) : \n",
    "        iterator = iterator + 1\n",
    "        continue\n",
    "        \n",
    "    Vocabulary_Seleksi_Yelp.append(Vocabulary_Yelp_Train[iterator])\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordDictionary_feature_importance_Train = dictionaryInitialize(\n",
    "            Clean_Yelp_Sentiment_Train,\n",
    "            Vocabulary_Seleksi_Yelp, \n",
    "            ngram_yelp_train,'transfer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(i,  )</th>\n",
       "      <th>( , d)</th>\n",
       "      <th>(d, o)</th>\n",
       "      <th>(o, n)</th>\n",
       "      <th>(n, t)</th>\n",
       "      <th>(t,  )</th>\n",
       "      <th>( , k)</th>\n",
       "      <th>(k, n)</th>\n",
       "      <th>(n, o)</th>\n",
       "      <th>(o, w)</th>\n",
       "      <th>...</th>\n",
       "      <th>(w, m, o)</th>\n",
       "      <th>(i, n, x)</th>\n",
       "      <th>(d, s, z)</th>\n",
       "      <th>(s, z, i)</th>\n",
       "      <th>(r, f, f)</th>\n",
       "      <th>(n, w,  )</th>\n",
       "      <th>(s, n, q)</th>\n",
       "      <th>(u, b, g)</th>\n",
       "      <th>(b, g, u)</th>\n",
       "      <th>(y, c, r)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 8197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (i,  )  ( , d)  (d, o)  (o, n)  (n, t)  (t,  )  ( , k)  (k, n)  (n, o)  \\\n",
       "0       4      11       6      13       7      19       1       1       5   \n",
       "1      10       7       6      10      13      21       1       1       1   \n",
       "\n",
       "   (o, w)  ...  (w, m, o)  (i, n, x)  (d, s, z)  (s, z, i)  (r, f, f)  \\\n",
       "0       1  ...          0          0          0          0          0   \n",
       "1       1  ...          0          0          0          0          0   \n",
       "\n",
       "   (n, w,  )  (s, n, q)  (u, b, g)  (b, g, u)  (y, c, r)  \n",
       "0          0          0          0          0          0  \n",
       "1          0          0          0          0          0  \n",
       "\n",
       "[2 rows x 8197 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([WordDictionaryCount_Yelp_Train[0],WordDictionaryCount_Yelp_Train[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(i,  )</th>\n",
       "      <th>( , d)</th>\n",
       "      <th>(d, o)</th>\n",
       "      <th>(o, n)</th>\n",
       "      <th>(n, t)</th>\n",
       "      <th>(t,  )</th>\n",
       "      <th>( , k)</th>\n",
       "      <th>(k, n)</th>\n",
       "      <th>(n, o)</th>\n",
       "      <th>(o, w)</th>\n",
       "      <th>...</th>\n",
       "      <th>(u, a, w)</th>\n",
       "      <th>(s, f, m)</th>\n",
       "      <th>(f, m, n)</th>\n",
       "      <th>(d, s, z)</th>\n",
       "      <th>(s, z, i)</th>\n",
       "      <th>(r, f, f)</th>\n",
       "      <th>(s, n, q)</th>\n",
       "      <th>(u, b, g)</th>\n",
       "      <th>(b, g, u)</th>\n",
       "      <th>(y, c, r)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 4147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (i,  )  ( , d)  (d, o)  (o, n)  (n, t)  (t,  )  ( , k)  (k, n)  (n, o)  \\\n",
       "0       4      11       6      13       7      19       1       1       5   \n",
       "1      10       7       6      10      13      21       1       1       1   \n",
       "\n",
       "   (o, w)  ...  (u, a, w)  (s, f, m)  (f, m, n)  (d, s, z)  (s, z, i)  \\\n",
       "0       1  ...          0          0          0          0          0   \n",
       "1       1  ...          0          0          0          0          0   \n",
       "\n",
       "   (r, f, f)  (s, n, q)  (u, b, g)  (b, g, u)  (y, c, r)  \n",
       "0          0          0          0          0          0  \n",
       "1          0          0          0          0          0  \n",
       "\n",
       "[2 rows x 4147 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([WordDictionary_feature_importance_Train[0],WordDictionary_feature_importance_Train[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordDictionary_feature_importance_Test = dictionaryInitialize(\n",
    "            Clean_Yelp_Sentiment_Test, \n",
    "            Vocabulary_Seleksi_Yelp, \n",
    "            ngram_yelp_test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountFrequency_Sentimen_Train_FI = getFrequencyTermPerData(WordDictionary_feature_importance_Train, ngram_yelp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountFrequency_Sentimen_Test_FI = getFrequencyTermPerData(WordDictionary_feature_importance_Test, ngram_yelp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF_Feature_Importance, number_term  = computeIDF(WordDictionary_feature_importance_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_Feature_importance_Train = getTFIDF(\n",
    "        WordDictionary_feature_importance_Train, \n",
    "        CountFrequency_Sentimen_Train_FI, \n",
    "        IDF_Feature_Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_Feature_importance_Test = getTFIDF(\n",
    "        WordDictionary_feature_importance_Test, \n",
    "        CountFrequency_Sentimen_Test_FI, \n",
    "        IDF_Feature_Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer_TF_Train = toVectorizeList(TFIDF_Feature_importance_Train)\n",
    "TFIDF_Feature_importance_Train = Vectorizer_TF_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer_TF_Test = toVectorizeList(TFIDF_Feature_importance_Test)\n",
    "TFIDF_Feature_importance_Test = Vectorizer_TF_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waktu Training: 21.631s\n"
     ]
    }
   ],
   "source": [
    "Waktu_Training = time()\n",
    "RF_Classifier_TF_FI = RandomForestClassifier(\n",
    "        max_depth= 5, n_estimators = 800, random_state=42,\n",
    "        bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_TF_FI.fit(TFIDF_Feature_importance_Train, Label_Yelp_Train)\n",
    "print(f\"\\nWaktu Training: {round(time()-Waktu_Training, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waktu prediksi (train): 1.55s\n",
      "waktu prediksi (test): 0.49s\n",
      "\n",
      "Skor Random Forest Train Interseksi : 0.9072\n",
      "Skor Random Forest Test Interseksi : 0.8608\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[1678  197]\n",
      " [ 151 1724]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      1875\n",
      "           1       0.90      0.92      0.91      1875\n",
      "\n",
      "    accuracy                           0.91      3750\n",
      "   macro avg       0.91      0.91      0.91      3750\n",
      "weighted avg       0.91      0.91      0.91      3750\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[544  81]\n",
      " [ 93 532]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       625\n",
      "           1       0.87      0.85      0.86       625\n",
      "\n",
      "    accuracy                           0.86      1250\n",
      "   macro avg       0.86      0.86      0.86      1250\n",
      "weighted avg       0.86      0.86      0.86      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Waktu_Predict_Train = time()\n",
    "Skor_Train_Seleksi_Yelp = RF_Classifier_TF_FI.score(TFIDF_Feature_importance_Train, Label_Yelp_Train)\n",
    "print(f\"waktu prediksi (train): {round(time()-Waktu_Predict_Train, 3)}s\")\n",
    "\n",
    "Waktu_Predict_Test = time()\n",
    "Skor_Test_Seleksi_Yelp = RF_Classifier_TF_FI.score(TFIDF_Feature_importance_Test, Label_Yelp_Test)\n",
    "print(f\"waktu prediksi (test): {round(time()-Waktu_Predict_Test, 3)}s\")\n",
    "\n",
    "print(\"\\nSkor Random Forest Train Interseksi : {}\".format(Skor_Train_Seleksi_Yelp))\n",
    "print(\"Skor Random Forest Test Interseksi : {}\".format(Skor_Test_Seleksi_Yelp))\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "\n",
    "RFClassifier_predict = RF_Classifier_TF_FI.predict(TFIDF_Feature_importance_Train)\n",
    "Confusion_matrix = confusion_matrix(Label_Yelp_Train, RFClassifier_predict)\n",
    "print(Confusion_matrix)\n",
    "print(metrics.classification_report(Label_Yelp_Train, RFClassifier_predict))\n",
    "\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFClassifier_predict = RF_Classifier_TF_FI.predict(TFIDF_Feature_importance_Test)\n",
    "Confusion_matrix = confusion_matrix(Label_Yelp_Test, RFClassifier_predict)\n",
    "print(Confusion_matrix)\n",
    "print(metrics.classification_report(Label_Yelp_Test, RFClassifier_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
