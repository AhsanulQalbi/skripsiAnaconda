{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKRIPSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import csv \n",
    "from nltk import ngrams\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, validation_curve,RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from matplotlib_venn import venn2\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(0)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "poster_Stemmer = nltk.PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baca file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baca csv\n",
    "data_train_amazon = pd.read_csv('Amazon_Train.csv')\n",
    "data_train_yelp = pd.read_csv('Yelp_Train.csv')\n",
    "data_test_amazon = pd.read_csv('Amazon_Test.csv')\n",
    "data_test_yelp = pd.read_csv('Yelp_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label                                           Sentimen\n",
      "0      0  Buyer beware This is a self-published book, an...\n",
      "1      0  The Worst! A complete waste of time. Typograph...\n",
      "2      0  Oh please I guess you have to be a romance nov...\n",
      "3      0  Awful beyond belief! I feel I have to write to...\n",
      "4      0  Another Abysmal Digital Copy Rather than scrat...\n",
      "\n",
      "\n",
      "   Label                                           Sentimen\n",
      "0      0  I don't know what Dr. Goldberg was like before...\n",
      "1      0  I'm writing this review to give you a heads up...\n",
      "2      0  Owning a driving range inside the city limits ...\n",
      "3      0  This place is absolute garbage...  Half of the...\n",
      "4      0  Used to go there for tires, brakes, etc.  Thei...\n"
     ]
    }
   ],
   "source": [
    "print(data_train_amazon.head())\n",
    "print(\"\\n\")\n",
    "print(data_train_yelp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label                                           Sentimen\n",
      "0      0  Overly complicated Being both a U.S. history b...\n",
      "1      0  Terrible Disappointment -- parts don't fit My ...\n",
      "2      0  Didn't hold up.....very disappointed I bought ...\n",
      "3      0  gene hates jezebel i love JLJ but this compila...\n",
      "4      0  Nice toy but ... My six-year-old loves space a...\n",
      "\n",
      "\n",
      "   Label                                           Sentimen\n",
      "0      0  My wife and I used to love Arriba's, til recen...\n",
      "1      0  You get what you pay for.  The food is inexpen...\n",
      "2      0  Unfortunately, yesterday's visit was one of th...\n",
      "3      0  I went into the Scottsdale location yesterday....\n",
      "4      0  It takes a lot for me to write a review and bl...\n"
     ]
    }
   ],
   "source": [
    "print(data_test_amazon.head())\n",
    "print(\"\\n\")\n",
    "print(data_test_yelp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing ke lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_Preprocessing_Amazon_Train = data_train_amazon\n",
    "data_Lowercase_Amazon_Train = []\n",
    "\n",
    "data_Preprocessing_Yelp_Train = data_train_yelp\n",
    "data_Lowercase_Yelp_Train = []\n",
    "\n",
    "while iterator < len(data_train_amazon) :\n",
    "    data_Lowercase_Amazon_Train.append(data_train_amazon.Sentimen[iterator].lower())\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_train_yelp) :\n",
    "    data_Lowercase_Yelp_Train.append(data_train_yelp.Sentimen[iterator].lower())\n",
    "    iterator = iterator + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_Preprocessing_Amazon_Test = data_test_amazon\n",
    "data_Lowercase_Amazon_Test = []\n",
    "\n",
    "data_Preprocessing_Yelp_Test = data_test_yelp\n",
    "data_Lowercase_Yelp_Test = []\n",
    "\n",
    "while iterator < len(data_test_amazon) :\n",
    "    data_Lowercase_Amazon_Test.append(data_test_amazon.Sentimen[iterator].lower())\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_test_yelp) :\n",
    "    data_Lowercase_Yelp_Test.append(data_test_yelp.Sentimen[iterator].lower())\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \n",
       "0  buyer beware this is a self-published book, an...  \n",
       "1  the worst! a complete waste of time. typograph...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief! i feel i have to write to...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon_Train['Lowercase'] = data_Lowercase_Amazon_Train\n",
    "data_Preprocessing_Amazon_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Overly complicated Being both a U.S. history b...</td>\n",
       "      <td>overly complicated being both a u.s. history b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Terrible Disappointment -- parts don't fit My ...</td>\n",
       "      <td>terrible disappointment -- parts don't fit my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Didn't hold up.....very disappointed I bought ...</td>\n",
       "      <td>didn't hold up.....very disappointed i bought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>gene hates jezebel i love JLJ but this compila...</td>\n",
       "      <td>gene hates jezebel i love jlj but this compila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Nice toy but ... My six-year-old loves space a...</td>\n",
       "      <td>nice toy but ... my six-year-old loves space a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Overly complicated Being both a U.S. history b...   \n",
       "1      0  Terrible Disappointment -- parts don't fit My ...   \n",
       "2      0  Didn't hold up.....very disappointed I bought ...   \n",
       "3      0  gene hates jezebel i love JLJ but this compila...   \n",
       "4      0  Nice toy but ... My six-year-old loves space a...   \n",
       "\n",
       "                                           Lowercase  \n",
       "0  overly complicated being both a u.s. history b...  \n",
       "1  terrible disappointment -- parts don't fit my ...  \n",
       "2  didn't hold up.....very disappointed i bought ...  \n",
       "3  gene hates jezebel i love jlj but this compila...  \n",
       "4  nice toy but ... my six-year-old loves space a...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon_Test['Lowercase'] = data_Lowercase_Amazon_Test\n",
    "data_Preprocessing_Amazon_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \n",
       "0  i don't know what dr. goldberg was like before...  \n",
       "1  i'm writing this review to give you a heads up...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage...  half of the...  \n",
       "4  used to go there for tires, brakes, etc.  thei...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Train['Lowercase'] = data_Lowercase_Yelp_Train\n",
    "data_Preprocessing_Yelp_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My wife and I used to love Arriba's, til recen...</td>\n",
       "      <td>my wife and i used to love arriba's, til recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>You get what you pay for.  The food is inexpen...</td>\n",
       "      <td>you get what you pay for.  the food is inexpen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Unfortunately, yesterday's visit was one of th...</td>\n",
       "      <td>unfortunately, yesterday's visit was one of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>I went into the Scottsdale location yesterday....</td>\n",
       "      <td>i went into the scottsdale location yesterday....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>It takes a lot for me to write a review and bl...</td>\n",
       "      <td>it takes a lot for me to write a review and bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  My wife and I used to love Arriba's, til recen...   \n",
       "1      0  You get what you pay for.  The food is inexpen...   \n",
       "2      0  Unfortunately, yesterday's visit was one of th...   \n",
       "3      0  I went into the Scottsdale location yesterday....   \n",
       "4      0  It takes a lot for me to write a review and bl...   \n",
       "\n",
       "                                           Lowercase  \n",
       "0  my wife and i used to love arriba's, til recen...  \n",
       "1  you get what you pay for.  the food is inexpen...  \n",
       "2  unfortunately, yesterday's visit was one of th...  \n",
       "3  i went into the scottsdale location yesterday....  \n",
       "4  it takes a lot for me to write a review and bl...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Test['Lowercase'] = data_Lowercase_Yelp_Test\n",
    "data_Preprocessing_Yelp_Test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghilangkan angka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_RemoveNumber_Amazon_Train = []\n",
    "\n",
    "data_RemoveNumber_Yelp_Train = []\n",
    "\n",
    "while iterator < len(data_Preprocessing_Amazon_Train) :\n",
    "    data_RemoveNumber_Amazon_Train.append(re.sub(r\"\\d+\", \"\",data_Preprocessing_Amazon_Train.Lowercase[iterator]))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_Preprocessing_Yelp_Train) :\n",
    "    data_RemoveNumber_Yelp_Train.append(re.sub(r\"\\d+\", \"\",data_Preprocessing_Yelp_Train.Lowercase[iterator]))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_RemoveNumber_Amazon_Test = []\n",
    "\n",
    "data_RemoveNumber_Yelp_Test = []\n",
    "\n",
    "while iterator < len(data_Preprocessing_Amazon_Test) :\n",
    "    data_RemoveNumber_Amazon_Test.append(re.sub(r\"\\d+\", \"\",data_Preprocessing_Amazon_Test.Lowercase[iterator]))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_Preprocessing_Yelp_Test) :\n",
    "    data_RemoveNumber_Yelp_Test.append(re.sub(r\"\\d+\", \"\",data_Preprocessing_Yelp_Test.Lowercase[iterator]))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                        RemoveNumber  \n",
       "0  buyer beware this is a self-published book, an...  \n",
       "1  the worst! a complete waste of time. typograph...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief! i feel i have to write to...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon_Train['RemoveNumber'] = data_RemoveNumber_Amazon_Train\n",
    "data_Preprocessing_Amazon_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Overly complicated Being both a U.S. history b...</td>\n",
       "      <td>overly complicated being both a u.s. history b...</td>\n",
       "      <td>overly complicated being both a u.s. history b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Terrible Disappointment -- parts don't fit My ...</td>\n",
       "      <td>terrible disappointment -- parts don't fit my ...</td>\n",
       "      <td>terrible disappointment -- parts don't fit my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Didn't hold up.....very disappointed I bought ...</td>\n",
       "      <td>didn't hold up.....very disappointed i bought ...</td>\n",
       "      <td>didn't hold up.....very disappointed i bought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>gene hates jezebel i love JLJ but this compila...</td>\n",
       "      <td>gene hates jezebel i love jlj but this compila...</td>\n",
       "      <td>gene hates jezebel i love jlj but this compila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Nice toy but ... My six-year-old loves space a...</td>\n",
       "      <td>nice toy but ... my six-year-old loves space a...</td>\n",
       "      <td>nice toy but ... my six-year-old loves space a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Overly complicated Being both a U.S. history b...   \n",
       "1      0  Terrible Disappointment -- parts don't fit My ...   \n",
       "2      0  Didn't hold up.....very disappointed I bought ...   \n",
       "3      0  gene hates jezebel i love JLJ but this compila...   \n",
       "4      0  Nice toy but ... My six-year-old loves space a...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  overly complicated being both a u.s. history b...   \n",
       "1  terrible disappointment -- parts don't fit my ...   \n",
       "2  didn't hold up.....very disappointed i bought ...   \n",
       "3  gene hates jezebel i love jlj but this compila...   \n",
       "4  nice toy but ... my six-year-old loves space a...   \n",
       "\n",
       "                                        RemoveNumber  \n",
       "0  overly complicated being both a u.s. history b...  \n",
       "1  terrible disappointment -- parts don't fit my ...  \n",
       "2  didn't hold up.....very disappointed i bought ...  \n",
       "3  gene hates jezebel i love jlj but this compila...  \n",
       "4  nice toy but ... my six-year-old loves space a...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon_Test['RemoveNumber'] = data_RemoveNumber_Amazon_Test\n",
    "data_Preprocessing_Amazon_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                        RemoveNumber  \n",
       "0  i don't know what dr. goldberg was like before...  \n",
       "1  i'm writing this review to give you a heads up...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage...  half of the...  \n",
       "4  used to go there for tires, brakes, etc.  thei...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Train['RemoveNumber'] = data_RemoveNumber_Yelp_Train\n",
    "data_Preprocessing_Yelp_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My wife and I used to love Arriba's, til recen...</td>\n",
       "      <td>my wife and i used to love arriba's, til recen...</td>\n",
       "      <td>my wife and i used to love arriba's, til recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>You get what you pay for.  The food is inexpen...</td>\n",
       "      <td>you get what you pay for.  the food is inexpen...</td>\n",
       "      <td>you get what you pay for.  the food is inexpen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Unfortunately, yesterday's visit was one of th...</td>\n",
       "      <td>unfortunately, yesterday's visit was one of th...</td>\n",
       "      <td>unfortunately, yesterday's visit was one of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>I went into the Scottsdale location yesterday....</td>\n",
       "      <td>i went into the scottsdale location yesterday....</td>\n",
       "      <td>i went into the scottsdale location yesterday....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>It takes a lot for me to write a review and bl...</td>\n",
       "      <td>it takes a lot for me to write a review and bl...</td>\n",
       "      <td>it takes a lot for me to write a review and bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  My wife and I used to love Arriba's, til recen...   \n",
       "1      0  You get what you pay for.  The food is inexpen...   \n",
       "2      0  Unfortunately, yesterday's visit was one of th...   \n",
       "3      0  I went into the Scottsdale location yesterday....   \n",
       "4      0  It takes a lot for me to write a review and bl...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  my wife and i used to love arriba's, til recen...   \n",
       "1  you get what you pay for.  the food is inexpen...   \n",
       "2  unfortunately, yesterday's visit was one of th...   \n",
       "3  i went into the scottsdale location yesterday....   \n",
       "4  it takes a lot for me to write a review and bl...   \n",
       "\n",
       "                                        RemoveNumber  \n",
       "0  my wife and i used to love arriba's, til recen...  \n",
       "1  you get what you pay for.  the food is inexpen...  \n",
       "2  unfortunately, yesterday's visit was one of th...  \n",
       "3  i went into the scottsdale location yesterday....  \n",
       "4  it takes a lot for me to write a review and bl...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Test['RemoveNumber'] = data_RemoveNumber_Yelp_Test\n",
    "data_Preprocessing_Yelp_Test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghilangkan tanda baca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_RemovePunctuation_Amazon_Train = []\n",
    "\n",
    "data_RemovePunctuation_Yelp_Train = []\n",
    "\n",
    "while iterator < len(data_Preprocessing_Amazon_Train) :\n",
    "    data_RemovePunctuation_Amazon_Train.append(data_Preprocessing_Amazon_Train.RemoveNumber[iterator].translate(str.maketrans('','', string.punctuation)))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_Preprocessing_Yelp_Train) :\n",
    "    data_RemovePunctuation_Yelp_Train.append(data_Preprocessing_Yelp_Train.RemoveNumber[iterator].translate(str.maketrans('','', string.punctuation)))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_RemovePunctuation_Amazon_Test = []\n",
    "\n",
    "data_RemovePunctuation_Yelp_Test = []\n",
    "\n",
    "while iterator < len(data_Preprocessing_Amazon_Test) :\n",
    "    data_RemovePunctuation_Amazon_Test.append(data_Preprocessing_Amazon_Test.RemoveNumber[iterator].translate(str.maketrans('','', string.punctuation)))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_Preprocessing_Yelp_Test) :\n",
    "    data_RemovePunctuation_Yelp_Test.append(data_Preprocessing_Yelp_Test.RemoveNumber[iterator].translate(str.maketrans('','', string.punctuation)))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a selfpublished book and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst a complete waste of time typographic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief i feel i have to write to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                   RemovePunctuation  \n",
       "0  buyer beware this is a selfpublished book and ...  \n",
       "1  the worst a complete waste of time typographic...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief i feel i have to write to ...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon_Train['RemovePunctuation'] = data_RemovePunctuation_Amazon_Train\n",
    "data_Preprocessing_Amazon_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Overly complicated Being both a U.S. history b...</td>\n",
       "      <td>overly complicated being both a u.s. history b...</td>\n",
       "      <td>overly complicated being both a u.s. history b...</td>\n",
       "      <td>overly complicated being both a us history buf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Terrible Disappointment -- parts don't fit My ...</td>\n",
       "      <td>terrible disappointment -- parts don't fit my ...</td>\n",
       "      <td>terrible disappointment -- parts don't fit my ...</td>\n",
       "      <td>terrible disappointment  parts dont fit my son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Didn't hold up.....very disappointed I bought ...</td>\n",
       "      <td>didn't hold up.....very disappointed i bought ...</td>\n",
       "      <td>didn't hold up.....very disappointed i bought ...</td>\n",
       "      <td>didnt hold upvery disappointed i bought this o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>gene hates jezebel i love JLJ but this compila...</td>\n",
       "      <td>gene hates jezebel i love jlj but this compila...</td>\n",
       "      <td>gene hates jezebel i love jlj but this compila...</td>\n",
       "      <td>gene hates jezebel i love jlj but this compila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Nice toy but ... My six-year-old loves space a...</td>\n",
       "      <td>nice toy but ... my six-year-old loves space a...</td>\n",
       "      <td>nice toy but ... my six-year-old loves space a...</td>\n",
       "      <td>nice toy but  my sixyearold loves space and to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Overly complicated Being both a U.S. history b...   \n",
       "1      0  Terrible Disappointment -- parts don't fit My ...   \n",
       "2      0  Didn't hold up.....very disappointed I bought ...   \n",
       "3      0  gene hates jezebel i love JLJ but this compila...   \n",
       "4      0  Nice toy but ... My six-year-old loves space a...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  overly complicated being both a u.s. history b...   \n",
       "1  terrible disappointment -- parts don't fit my ...   \n",
       "2  didn't hold up.....very disappointed i bought ...   \n",
       "3  gene hates jezebel i love jlj but this compila...   \n",
       "4  nice toy but ... my six-year-old loves space a...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  overly complicated being both a u.s. history b...   \n",
       "1  terrible disappointment -- parts don't fit my ...   \n",
       "2  didn't hold up.....very disappointed i bought ...   \n",
       "3  gene hates jezebel i love jlj but this compila...   \n",
       "4  nice toy but ... my six-year-old loves space a...   \n",
       "\n",
       "                                   RemovePunctuation  \n",
       "0  overly complicated being both a us history buf...  \n",
       "1  terrible disappointment  parts dont fit my son...  \n",
       "2  didnt hold upvery disappointed i bought this o...  \n",
       "3  gene hates jezebel i love jlj but this compila...  \n",
       "4  nice toy but  my sixyearold loves space and to...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon_Test['RemovePunctuation'] = data_RemovePunctuation_Amazon_Test\n",
    "data_Preprocessing_Amazon_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i dont know what dr goldberg was like before  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>im writing this review to give you a heads up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage  half of the te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires brakes etc  their p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                   RemovePunctuation  \n",
       "0  i dont know what dr goldberg was like before  ...  \n",
       "1  im writing this review to give you a heads up ...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage  half of the te...  \n",
       "4  used to go there for tires brakes etc  their p...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Train['RemovePunctuation'] = data_RemovePunctuation_Yelp_Train\n",
    "data_Preprocessing_Yelp_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My wife and I used to love Arriba's, til recen...</td>\n",
       "      <td>my wife and i used to love arriba's, til recen...</td>\n",
       "      <td>my wife and i used to love arriba's, til recen...</td>\n",
       "      <td>my wife and i used to love arribas til recentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>You get what you pay for.  The food is inexpen...</td>\n",
       "      <td>you get what you pay for.  the food is inexpen...</td>\n",
       "      <td>you get what you pay for.  the food is inexpen...</td>\n",
       "      <td>you get what you pay for  the food is inexpens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Unfortunately, yesterday's visit was one of th...</td>\n",
       "      <td>unfortunately, yesterday's visit was one of th...</td>\n",
       "      <td>unfortunately, yesterday's visit was one of th...</td>\n",
       "      <td>unfortunately yesterdays visit was one of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>I went into the Scottsdale location yesterday....</td>\n",
       "      <td>i went into the scottsdale location yesterday....</td>\n",
       "      <td>i went into the scottsdale location yesterday....</td>\n",
       "      <td>i went into the scottsdale location yesterday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>It takes a lot for me to write a review and bl...</td>\n",
       "      <td>it takes a lot for me to write a review and bl...</td>\n",
       "      <td>it takes a lot for me to write a review and bl...</td>\n",
       "      <td>it takes a lot for me to write a review and bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  My wife and I used to love Arriba's, til recen...   \n",
       "1      0  You get what you pay for.  The food is inexpen...   \n",
       "2      0  Unfortunately, yesterday's visit was one of th...   \n",
       "3      0  I went into the Scottsdale location yesterday....   \n",
       "4      0  It takes a lot for me to write a review and bl...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  my wife and i used to love arriba's, til recen...   \n",
       "1  you get what you pay for.  the food is inexpen...   \n",
       "2  unfortunately, yesterday's visit was one of th...   \n",
       "3  i went into the scottsdale location yesterday....   \n",
       "4  it takes a lot for me to write a review and bl...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  my wife and i used to love arriba's, til recen...   \n",
       "1  you get what you pay for.  the food is inexpen...   \n",
       "2  unfortunately, yesterday's visit was one of th...   \n",
       "3  i went into the scottsdale location yesterday....   \n",
       "4  it takes a lot for me to write a review and bl...   \n",
       "\n",
       "                                   RemovePunctuation  \n",
       "0  my wife and i used to love arribas til recentl...  \n",
       "1  you get what you pay for  the food is inexpens...  \n",
       "2  unfortunately yesterdays visit was one of the ...  \n",
       "3  i went into the scottsdale location yesterday ...  \n",
       "4  it takes a lot for me to write a review and bl...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Test['RemovePunctuation'] = data_RemovePunctuation_Yelp_Test\n",
    "data_Preprocessing_Yelp_Test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghilangkan Non alfabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "\n",
    "data_Regex_alpabet_only_Amazon_Train = []\n",
    "\n",
    "data_Regex_alpabet_only_Yelp_Train = []\n",
    "\n",
    "\n",
    "while iterator < len(data_Preprocessing_Amazon_Train) :\n",
    "    data_Regex_alpabet_only_Amazon_Train.append(\" \".join(re.findall(\"[a-zA-Z]+\", data_Preprocessing_Amazon_Train.RemovePunctuation[iterator])))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_Preprocessing_Yelp_Train) :\n",
    "    data_Regex_alpabet_only_Yelp_Train.append(\" \".join(re.findall(r\"[a-zA-Z]+\", data_Preprocessing_Yelp_Train.RemovePunctuation[iterator])))\n",
    "    iterator = iterator + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "\n",
    "data_Regex_alpabet_only_Amazon_Test = []\n",
    "\n",
    "data_Regex_alpabet_only_Yelp_Test = []\n",
    "\n",
    "\n",
    "while iterator < len(data_Preprocessing_Amazon_Test) :\n",
    "    data_Regex_alpabet_only_Amazon_Test.append(\" \".join(re.findall(\"[a-zA-Z]+\", data_Preprocessing_Amazon_Test.RemovePunctuation[iterator])))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_Preprocessing_Yelp_Test) :\n",
    "    data_Regex_alpabet_only_Yelp_Test.append(\" \".join(re.findall(r\"[a-zA-Z]+\", data_Preprocessing_Yelp_Test.RemovePunctuation[iterator])))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "      <th>Regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a selfpublished book and ...</td>\n",
       "      <td>buyer beware this is a selfpublished book and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst a complete waste of time typographic...</td>\n",
       "      <td>the worst a complete waste of time typographic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief i feel i have to write to ...</td>\n",
       "      <td>awful beyond belief i feel i have to write to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                   RemovePunctuation  \\\n",
       "0  buyer beware this is a selfpublished book and ...   \n",
       "1  the worst a complete waste of time typographic...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief i feel i have to write to ...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                               Regex  \n",
       "0  buyer beware this is a selfpublished book and ...  \n",
       "1  the worst a complete waste of time typographic...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief i feel i have to write to ...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon_Train['Regex'] = data_Regex_alpabet_only_Amazon_Train\n",
    "data_Preprocessing_Amazon_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "      <th>Regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Overly complicated Being both a U.S. history b...</td>\n",
       "      <td>overly complicated being both a u.s. history b...</td>\n",
       "      <td>overly complicated being both a u.s. history b...</td>\n",
       "      <td>overly complicated being both a us history buf...</td>\n",
       "      <td>overly complicated being both a us history buf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Terrible Disappointment -- parts don't fit My ...</td>\n",
       "      <td>terrible disappointment -- parts don't fit my ...</td>\n",
       "      <td>terrible disappointment -- parts don't fit my ...</td>\n",
       "      <td>terrible disappointment  parts dont fit my son...</td>\n",
       "      <td>terrible disappointment parts dont fit my son ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Didn't hold up.....very disappointed I bought ...</td>\n",
       "      <td>didn't hold up.....very disappointed i bought ...</td>\n",
       "      <td>didn't hold up.....very disappointed i bought ...</td>\n",
       "      <td>didnt hold upvery disappointed i bought this o...</td>\n",
       "      <td>didnt hold upvery disappointed i bought this o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>gene hates jezebel i love JLJ but this compila...</td>\n",
       "      <td>gene hates jezebel i love jlj but this compila...</td>\n",
       "      <td>gene hates jezebel i love jlj but this compila...</td>\n",
       "      <td>gene hates jezebel i love jlj but this compila...</td>\n",
       "      <td>gene hates jezebel i love jlj but this compila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Nice toy but ... My six-year-old loves space a...</td>\n",
       "      <td>nice toy but ... my six-year-old loves space a...</td>\n",
       "      <td>nice toy but ... my six-year-old loves space a...</td>\n",
       "      <td>nice toy but  my sixyearold loves space and to...</td>\n",
       "      <td>nice toy but my sixyearold loves space and to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Overly complicated Being both a U.S. history b...   \n",
       "1      0  Terrible Disappointment -- parts don't fit My ...   \n",
       "2      0  Didn't hold up.....very disappointed I bought ...   \n",
       "3      0  gene hates jezebel i love JLJ but this compila...   \n",
       "4      0  Nice toy but ... My six-year-old loves space a...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  overly complicated being both a u.s. history b...   \n",
       "1  terrible disappointment -- parts don't fit my ...   \n",
       "2  didn't hold up.....very disappointed i bought ...   \n",
       "3  gene hates jezebel i love jlj but this compila...   \n",
       "4  nice toy but ... my six-year-old loves space a...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  overly complicated being both a u.s. history b...   \n",
       "1  terrible disappointment -- parts don't fit my ...   \n",
       "2  didn't hold up.....very disappointed i bought ...   \n",
       "3  gene hates jezebel i love jlj but this compila...   \n",
       "4  nice toy but ... my six-year-old loves space a...   \n",
       "\n",
       "                                   RemovePunctuation  \\\n",
       "0  overly complicated being both a us history buf...   \n",
       "1  terrible disappointment  parts dont fit my son...   \n",
       "2  didnt hold upvery disappointed i bought this o...   \n",
       "3  gene hates jezebel i love jlj but this compila...   \n",
       "4  nice toy but  my sixyearold loves space and to...   \n",
       "\n",
       "                                               Regex  \n",
       "0  overly complicated being both a us history buf...  \n",
       "1  terrible disappointment parts dont fit my son ...  \n",
       "2  didnt hold upvery disappointed i bought this o...  \n",
       "3  gene hates jezebel i love jlj but this compila...  \n",
       "4  nice toy but my sixyearold loves space and to ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon_Test['Regex'] = data_Regex_alpabet_only_Amazon_Test\n",
    "data_Preprocessing_Amazon_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "      <th>Regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i dont know what dr goldberg was like before  ...</td>\n",
       "      <td>i dont know what dr goldberg was like before m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>im writing this review to give you a heads up ...</td>\n",
       "      <td>im writing this review to give you a heads up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage  half of the te...</td>\n",
       "      <td>this place is absolute garbage half of the tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires brakes etc  their p...</td>\n",
       "      <td>used to go there for tires brakes etc their pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                   RemovePunctuation  \\\n",
       "0  i dont know what dr goldberg was like before  ...   \n",
       "1  im writing this review to give you a heads up ...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage  half of the te...   \n",
       "4  used to go there for tires brakes etc  their p...   \n",
       "\n",
       "                                               Regex  \n",
       "0  i dont know what dr goldberg was like before m...  \n",
       "1  im writing this review to give you a heads up ...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage half of the tee...  \n",
       "4  used to go there for tires brakes etc their pr...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Train['Regex'] = data_Regex_alpabet_only_Yelp_Train\n",
    "data_Preprocessing_Yelp_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "      <th>Regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My wife and I used to love Arriba's, til recen...</td>\n",
       "      <td>my wife and i used to love arriba's, til recen...</td>\n",
       "      <td>my wife and i used to love arriba's, til recen...</td>\n",
       "      <td>my wife and i used to love arribas til recentl...</td>\n",
       "      <td>my wife and i used to love arribas til recentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>You get what you pay for.  The food is inexpen...</td>\n",
       "      <td>you get what you pay for.  the food is inexpen...</td>\n",
       "      <td>you get what you pay for.  the food is inexpen...</td>\n",
       "      <td>you get what you pay for  the food is inexpens...</td>\n",
       "      <td>you get what you pay for the food is inexpensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Unfortunately, yesterday's visit was one of th...</td>\n",
       "      <td>unfortunately, yesterday's visit was one of th...</td>\n",
       "      <td>unfortunately, yesterday's visit was one of th...</td>\n",
       "      <td>unfortunately yesterdays visit was one of the ...</td>\n",
       "      <td>unfortunately yesterdays visit was one of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>I went into the Scottsdale location yesterday....</td>\n",
       "      <td>i went into the scottsdale location yesterday....</td>\n",
       "      <td>i went into the scottsdale location yesterday....</td>\n",
       "      <td>i went into the scottsdale location yesterday ...</td>\n",
       "      <td>i went into the scottsdale location yesterday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>It takes a lot for me to write a review and bl...</td>\n",
       "      <td>it takes a lot for me to write a review and bl...</td>\n",
       "      <td>it takes a lot for me to write a review and bl...</td>\n",
       "      <td>it takes a lot for me to write a review and bl...</td>\n",
       "      <td>it takes a lot for me to write a review and bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  My wife and I used to love Arriba's, til recen...   \n",
       "1      0  You get what you pay for.  The food is inexpen...   \n",
       "2      0  Unfortunately, yesterday's visit was one of th...   \n",
       "3      0  I went into the Scottsdale location yesterday....   \n",
       "4      0  It takes a lot for me to write a review and bl...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  my wife and i used to love arriba's, til recen...   \n",
       "1  you get what you pay for.  the food is inexpen...   \n",
       "2  unfortunately, yesterday's visit was one of th...   \n",
       "3  i went into the scottsdale location yesterday....   \n",
       "4  it takes a lot for me to write a review and bl...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  my wife and i used to love arriba's, til recen...   \n",
       "1  you get what you pay for.  the food is inexpen...   \n",
       "2  unfortunately, yesterday's visit was one of th...   \n",
       "3  i went into the scottsdale location yesterday....   \n",
       "4  it takes a lot for me to write a review and bl...   \n",
       "\n",
       "                                   RemovePunctuation  \\\n",
       "0  my wife and i used to love arribas til recentl...   \n",
       "1  you get what you pay for  the food is inexpens...   \n",
       "2  unfortunately yesterdays visit was one of the ...   \n",
       "3  i went into the scottsdale location yesterday ...   \n",
       "4  it takes a lot for me to write a review and bl...   \n",
       "\n",
       "                                               Regex  \n",
       "0  my wife and i used to love arribas til recentl...  \n",
       "1  you get what you pay for the food is inexpensi...  \n",
       "2  unfortunately yesterdays visit was one of the ...  \n",
       "3  i went into the scottsdale location yesterday ...  \n",
       "4  it takes a lot for me to write a review and bl...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp_Test['Regex'] = data_Regex_alpabet_only_Yelp_Test\n",
    "data_Preprocessing_Yelp_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_Amazon_Sentiment_Train = data_Preprocessing_Amazon_Train['Regex']\n",
    "Clean_Yelp_Sentiment_Train = data_Preprocessing_Yelp_Train['Regex']\n",
    "Label_Amazon_Train = data_Preprocessing_Amazon_Train['Label']\n",
    "Label_Yelp_Train = data_Preprocessing_Yelp_Train['Label']\n",
    "\n",
    "Clean_Amazon_Sentiment_Test = data_Preprocessing_Amazon_Test['Regex']\n",
    "Clean_Yelp_Sentiment_Test = data_Preprocessing_Yelp_Test['Regex']\n",
    "Label_Amazon_Test = data_Preprocessing_Amazon_Test['Label']\n",
    "Label_Yelp_Test = data_Preprocessing_Yelp_Test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf = tfidfvectorizer()\n",
    "# tf.fit(train)\n",
    "# trainx = tf.transform(train)\n",
    "# testx = tf.transform(test)\n",
    "\n",
    "vectorizer_Amazon = TfidfVectorizer(ngram_range=(2,3), analyzer = 'char')\n",
    "vectorizer_Amazon.fit(Clean_Amazon_Sentiment_Train)\n",
    "Data_Train_Amazon = vectorizer_Amazon.transform(Clean_Amazon_Sentiment_Train).toarray()\n",
    "Vocabulary_Train_Amazon = vectorizer_Amazon.get_feature_names()\n",
    "Data_Test_Amazon = vectorizer_Amazon.transform(Clean_Amazon_Sentiment_Test).toarray()\n",
    "\n",
    "vectorizer_Yelp = TfidfVectorizer(ngram_range=(2,3),analyzer = 'char' )\n",
    "vectorizer_Yelp.fit(Clean_Yelp_Sentiment_Train)\n",
    "Data_Train_Yelp = vectorizer_Yelp.transform(Clean_Yelp_Sentiment_Train).toarray()\n",
    "Vocabulary_Train_Yelp = vectorizer_Yelp.get_feature_names()\n",
    "Data_Test_Yelp = vectorizer_Yelp.transform(Clean_Yelp_Sentiment_Test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a    aa        ab        ac        ad   ae        af  \\\n",
      "0     0.174884  0.079896  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "1     0.149341  0.046906  0.0  0.044125  0.052581  0.055971  0.0  0.000000   \n",
      "2     0.122904  0.056149  0.0  0.026410  0.000000  0.000000  0.0  0.033775   \n",
      "3     0.107078  0.041393  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "4     0.121365  0.022871  0.0  0.014344  0.017092  0.000000  0.0  0.000000   \n",
      "...        ...       ...  ...       ...       ...       ...  ...       ...   \n",
      "7495  0.082949  0.014887  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "7496  0.119551  0.033377  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "7497  0.139474  0.087614  0.0  0.029971  0.000000  0.000000  0.0  0.000000   \n",
      "7498  0.103292  0.000000  0.0  0.000000  0.072736  0.000000  0.0  0.000000   \n",
      "7499  0.040737  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "\n",
      "            ag   ah  ...  zzf  zzi  zzk  zzl  zzo  zzs  zzt  zzu  zzy  zzz  \n",
      "0     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.024274  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "7495  0.034922  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7496  0.039147  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7497  0.037367  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7498  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7499  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[7500 rows x 9321 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Amazon_Train = pd.DataFrame(Data_Train_Amazon, columns = Vocabulary_Train_Amazon)\n",
    "print (DataFrame_Amazon_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a    aa        ab   ac        ad   ae        af  \\\n",
      "0     0.145900  0.061100  0.0  0.019159  0.0  0.048606  0.0  0.024502   \n",
      "1     0.087064  0.013673  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2     0.090990  0.048992  0.0  0.015362  0.0  0.000000  0.0  0.039293   \n",
      "3     0.086429  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "4     0.085100  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "...        ...       ...  ...       ...  ...       ...  ...       ...   \n",
      "2495  0.048423  0.015209  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2496  0.051493  0.021564  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2497  0.109906  0.046027  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2498  0.033166  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2499  0.089913  0.045185  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "\n",
      "            ag   ah  ...  zzf  zzi  zzk  zzl  zzo  zzs  zzt  zzu  zzy  zzz  \n",
      "0     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "2495  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2496  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2497  0.053983  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2498  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2499  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2500 rows x 9321 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Amazon_Test = pd.DataFrame(Data_Test_Amazon, columns = Vocabulary_Train_Amazon)\n",
    "print (DataFrame_Amazon_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a    aa        ab       ac        ad   ae        af  \\\n",
      "0     0.171214  0.048025  0.0  0.036015  0.00000  0.017194  0.0  0.014425   \n",
      "1     0.140388  0.044025  0.0  0.012840  0.00000  0.036779  0.0  0.000000   \n",
      "2     0.159648  0.054833  0.0  0.011994  0.04579  0.017178  0.0  0.000000   \n",
      "3     0.190184  0.025403  0.0  0.022225  0.00000  0.000000  0.0  0.026706   \n",
      "4     0.059365  0.035682  0.0  0.000000  0.00000  0.000000  0.0  0.000000   \n",
      "...        ...       ...  ...       ...      ...       ...  ...       ...   \n",
      "7495  0.103979  0.031249  0.0  0.000000  0.00000  0.000000  0.0  0.000000   \n",
      "7496  0.157036  0.043564  0.0  0.000000  0.00000  0.000000  0.0  0.000000   \n",
      "7497  0.043994  0.000000  0.0  0.000000  0.00000  0.000000  0.0  0.000000   \n",
      "7498  0.061627  0.000000  0.0  0.000000  0.00000  0.000000  0.0  0.000000   \n",
      "7499  0.170437  0.083817  0.0  0.016296  0.00000  0.000000  0.0  0.019582   \n",
      "\n",
      "       ag   ah  ...  zzb  zzc  zze  zzi  zzl  zzn  zzo  zzu  zzy  zzz  \n",
      "0     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "7495  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7496  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7497  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7498  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7499  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[7500 rows x 9399 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Yelp_Train = pd.DataFrame(Data_Train_Yelp, columns = Vocabulary_Train_Yelp)\n",
    "print (DataFrame_Yelp_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a    aa        ab        ac        ad   ae        af  \\\n",
      "0     0.164301  0.026335  0.0  0.023041  0.000000  0.000000  0.0  0.013843   \n",
      "1     0.078854  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "2     0.090357  0.046551  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "3     0.120136  0.009628  0.0  0.000000  0.000000  0.000000  0.0  0.020244   \n",
      "4     0.164085  0.024055  0.0  0.000000  0.000000  0.000000  0.0  0.010116   \n",
      "...        ...       ...  ...       ...       ...       ...  ...       ...   \n",
      "2495  0.120832  0.016139  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "2496  0.090460  0.036248  0.0  0.000000  0.000000  0.090846  0.0  0.000000   \n",
      "2497  0.181204  0.019803  0.0  0.000000  0.000000  0.000000  0.0  0.041637   \n",
      "2498  0.169448  0.040739  0.0  0.011881  0.015120  0.000000  0.0  0.014276   \n",
      "2499  0.154315  0.037101  0.0  0.000000  0.041309  0.000000  0.0  0.000000   \n",
      "\n",
      "            ag      ah  ...  zzb  zzc  zze  zzi  zzl  zzn  zzo  zzu  zzy  zzz  \n",
      "0     0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.030708  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...        ...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "2495  0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2496  0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2497  0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2498  0.000000  0.0273  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2499  0.000000  0.0000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2500 rows x 9399 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Yelp_Test = pd.DataFrame(Data_Test_Yelp, columns = Vocabulary_Train_Yelp)\n",
    "print (DataFrame_Yelp_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waktu Training Amazon: 47.345s\n"
     ]
    }
   ],
   "source": [
    "Waktu_Training = time()\n",
    "RF_Classifier_Amazon = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Amazon.fit(Data_Train_Amazon, Label_Amazon_Train)\n",
    "print(f\"\\nWaktu Training Amazon: {round(time()-Waktu_Training, 3)}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waktu prediksi (train): 0.868s\n",
      "waktu prediksi (test): 0.31s\n",
      "\n",
      "Skor Random Forest Train Amazon : 0.8558666666666667\n",
      "Skor Random Forest Test Amazon : 0.8112\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[3236  514]\n",
      " [ 567 3183]]\n",
      "\n",
      "Accuracy Train:  0.8558666666666667\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      3750\n",
      "           1       0.86      0.85      0.85      3750\n",
      "\n",
      "    accuracy                           0.86      7500\n",
      "   macro avg       0.86      0.86      0.86      7500\n",
      "weighted avg       0.86      0.86      0.86      7500\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[1022  228]\n",
      " [ 244 1006]]\n",
      "\n",
      "Accuracy TEST:  0.8112\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1250\n",
      "           1       0.82      0.80      0.81      1250\n",
      "\n",
      "    accuracy                           0.81      2500\n",
      "   macro avg       0.81      0.81      0.81      2500\n",
      "weighted avg       0.81      0.81      0.81      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Waktu_Predict_Train = time()\n",
    "Skor_Train_Amazon = RF_Classifier_Amazon.score(Data_Train_Amazon, Label_Amazon_Train)\n",
    "print(f\"waktu prediksi (train): {round(time()-Waktu_Predict_Train, 3)}s\")\n",
    "\n",
    "Waktu_Predict_Test = time()\n",
    "Skor_Test_Amazon = RF_Classifier_Amazon.score(Data_Test_Amazon, Label_Amazon_Test)\n",
    "print(f\"waktu prediksi (test): {round(time()-Waktu_Predict_Test, 3)}s\")\n",
    "\n",
    "print(\"\\nSkor Random Forest Train Amazon : {}\".format(Skor_Train_Amazon))\n",
    "print(\"Skor Random Forest Test Amazon : {}\\n\\n\".format(Skor_Test_Amazon))\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Amazon.predict(Data_Train_Amazon)\n",
    "Confusion_matrix = confusion_matrix(Label_Amazon_Train, RFC_predict)\n",
    "print(Confusion_matrix)\n",
    "print(\"\\nAccuracy Train: \", accuracy_score(Label_Amazon_Train, RFC_predict))\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(Label_Amazon_Train, RFC_predict))\n",
    "\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Amazon.predict(Data_Test_Amazon)\n",
    "Confusion_matrix = confusion_matrix(Label_Amazon_Test, RFC_predict)\n",
    "print(Confusion_matrix)\n",
    "print(\"\\nAccuracy TEST: \", accuracy_score(Label_Amazon_Test, RFC_predict))\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(Label_Amazon_Test, RFC_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waktu Training Yelp: 49.88s\n"
     ]
    }
   ],
   "source": [
    "Waktu_Training = time()\n",
    "RF_Classifier_Yelp = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Yelp.fit(Data_Train_Yelp, Label_Yelp_Train)\n",
    "print(f\"\\nWaktu Training Yelp: {round(time()-Waktu_Training, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waktu prediksi (train): 0.899s\n",
      "waktu prediksi (test): 0.319s\n",
      "\n",
      "Skor Random Forest Train Yelp : 0.8686666666666667\n",
      "Skor Random Forest Test Yelp : 0.838\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[3152  598]\n",
      " [ 387 3363]]\n",
      "\n",
      "Accuracy Train:  0.8686666666666667\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86      3750\n",
      "           1       0.85      0.90      0.87      3750\n",
      "\n",
      "    accuracy                           0.87      7500\n",
      "   macro avg       0.87      0.87      0.87      7500\n",
      "weighted avg       0.87      0.87      0.87      7500\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[1036  214]\n",
      " [ 191 1059]]\n",
      "\n",
      "Accuracy Test:  0.838\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1250\n",
      "           1       0.83      0.85      0.84      1250\n",
      "\n",
      "    accuracy                           0.84      2500\n",
      "   macro avg       0.84      0.84      0.84      2500\n",
      "weighted avg       0.84      0.84      0.84      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Waktu_Predict_Train = time()\n",
    "Skor_Train_Yelp = RF_Classifier_Yelp.score(Data_Train_Yelp, Label_Yelp_Train)\n",
    "print(f\"waktu prediksi (train): {round(time()-Waktu_Predict_Train, 3)}s\")\n",
    "\n",
    "Waktu_Predict_Test = time()\n",
    "Skor_Test_Yelp = RF_Classifier_Yelp.score(Data_Test_Yelp, Label_Yelp_Test)\n",
    "print(f\"waktu prediksi (test): {round(time()-Waktu_Predict_Test, 3)}s\")\n",
    "\n",
    "print(\"\\nSkor Random Forest Train Yelp : {}\".format(Skor_Train_Yelp))\n",
    "print(\"Skor Random Forest Test Yelp : {}\".format(Skor_Test_Yelp))\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Yelp.predict(Data_Train_Yelp)\n",
    "Confusion_matrix = confusion_matrix(Label_Yelp_Train, RFC_predict)\n",
    "print(\"\\n\\n\")\n",
    "print(Confusion_matrix)\n",
    "print(\"\\nAccuracy Train: \", accuracy_score(Label_Yelp_Train, RFC_predict))\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(Label_Yelp_Train, RFC_predict))\n",
    "\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Yelp.predict(Data_Test_Yelp)\n",
    "Confusion_matrix = confusion_matrix(Label_Yelp_Test, RFC_predict)\n",
    "print(Confusion_matrix)\n",
    "print(\"\\nAccuracy Test: \", accuracy_score(Label_Yelp_Test, RFC_predict))\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(Label_Yelp_Test, RFC_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_Importance_Amazon = []\n",
    "iterator = 0\n",
    "length = len (Vocabulary_Train_Amazon)\n",
    "\n",
    "while iterator < length : \n",
    "    if RF_Classifier_Amazon.feature_importances_[iterator] > 0 :\n",
    "        Vocabulary_Importance_Amazon.append(Vocabulary_Train_Amazon[iterator])\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat Vectorizer baru dari data fitur importance only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_importance_amazon = TfidfVectorizer(vocabulary = Vocabulary_Importance_Amazon, ngram_range=(2,3),analyzer = 'char')\n",
    "\n",
    "vectorizer_importance_amazon.fit(Clean_Amazon_Sentiment_Train)\n",
    "Vocabulary_Importance_Amazon_Train = vectorizer_importance_amazon.get_feature_names()\n",
    "\n",
    "Data_Train_Importance_Amazon = vectorizer_importance_amazon.transform(Clean_Amazon_Sentiment_Train).toarray()\n",
    "Data_Test_Importance_Amazon = vectorizer_importance_amazon.transform(Clean_Amazon_Sentiment_Test).toarray()\n",
    "\n",
    "# tf = tfidfvectorizer()\n",
    "# tf.fit(train)\n",
    "# trainx = tf.transform(train)\n",
    "# testx = tf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a         ab        ac        ad        af        ag  \\\n",
      "0     0.183251  0.083719  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1     0.159160  0.049990  0.047026  0.056038  0.059651  0.000000  0.000000   \n",
      "2     0.128072  0.058510  0.027521  0.000000  0.000000  0.035195  0.000000   \n",
      "3     0.108944  0.042114  0.000000  0.000000  0.000000  0.000000  0.024697   \n",
      "4     0.126907  0.023916  0.014999  0.017873  0.000000  0.000000  0.000000   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "7495  0.088650  0.015911  0.000000  0.000000  0.000000  0.000000  0.037322   \n",
      "7496  0.123625  0.034514  0.000000  0.000000  0.000000  0.000000  0.040481   \n",
      "7497  0.147715  0.092790  0.031742  0.000000  0.000000  0.000000  0.039574   \n",
      "7498  0.114867  0.000000  0.000000  0.080887  0.000000  0.000000  0.000000   \n",
      "7499  0.044905  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "       ah   ai        al  ...  zer   zi  zil  zin        zo       zon  zor  \\\n",
      "0     0.0  0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.030906  0.031941  0.0   \n",
      "1     0.0  0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "2     0.0  0.0  0.061721  ...  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "3     0.0  0.0  0.014808  ...  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "4     0.0  0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.023544  0.024332  0.0   \n",
      "...   ...  ...       ...  ...  ...  ...  ...  ...       ...       ...  ...   \n",
      "7495  0.0  0.0  0.044757  ...  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "7496  0.0  0.0  0.048545  ...  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "7497  0.0  0.0  0.011865  ...  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "7498  0.0  0.0  0.050744  ...  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "7499  0.0  0.0  0.039674  ...  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "\n",
      "      zy    zz  zza  \n",
      "0     0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.0  \n",
      "...   ...  ...  ...  \n",
      "7495  0.0  0.0  0.0  \n",
      "7496  0.0  0.0  0.0  \n",
      "7497  0.0  0.0  0.0  \n",
      "7498  0.0  0.0  0.0  \n",
      "7499  0.0  0.0  0.0  \n",
      "\n",
      "[7500 rows x 2892 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Importance_Amazon = pd.DataFrame(Data_Train_Importance_Amazon, columns = Vocabulary_Importance_Amazon_Train)\n",
    "print (DataFrame_Importance_Amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a         ab   ac        ad        af        ag   ah  \\\n",
      "0     0.155415  0.065085  0.020409  0.0  0.051776  0.026100  0.000000  0.0   \n",
      "1     0.089220  0.014011  0.000000  0.0  0.000000  0.000000  0.000000  0.0   \n",
      "2     0.097597  0.052549  0.016478  0.0  0.000000  0.042147  0.000000  0.0   \n",
      "3     0.100683  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.0   \n",
      "4     0.092838  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.0   \n",
      "...        ...       ...       ...  ...       ...       ...       ...  ...   \n",
      "2495  0.049866  0.015662  0.000000  0.0  0.000000  0.000000  0.000000  0.0   \n",
      "2496  0.053499  0.022404  0.000000  0.0  0.000000  0.000000  0.000000  0.0   \n",
      "2497  0.119444  0.050021  0.000000  0.0  0.000000  0.000000  0.058668  0.0   \n",
      "2498  0.036636  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.0   \n",
      "2499  0.093751  0.047114  0.000000  0.0  0.000000  0.000000  0.000000  0.0   \n",
      "\n",
      "       ai        al  ...  zer        zi  zil       zin   zo  zon  zor  zy   \\\n",
      "0     0.0  0.015257  ...  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "1     0.0  0.019707  ...  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "2     0.0  0.000000  ...  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "3     0.0  0.044478  ...  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "4     0.0  0.027342  ...  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "...   ...       ...  ...  ...       ...  ...       ...  ...  ...  ...  ...   \n",
      "2495  0.0  0.000000  ...  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "2496  0.0  0.000000  ...  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "2497  0.0  0.000000  ...  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "2498  0.0  0.000000  ...  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "2499  0.0  0.033133  ...  0.0  0.071989  0.0  0.074261  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       zz  zza  \n",
      "0     0.0  0.0  \n",
      "1     0.0  0.0  \n",
      "2     0.0  0.0  \n",
      "3     0.0  0.0  \n",
      "4     0.0  0.0  \n",
      "...   ...  ...  \n",
      "2495  0.0  0.0  \n",
      "2496  0.0  0.0  \n",
      "2497  0.0  0.0  \n",
      "2498  0.0  0.0  \n",
      "2499  0.0  0.0  \n",
      "\n",
      "[2500 rows x 2892 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Importance_Amazon_Test = pd.DataFrame(Data_Test_Importance_Amazon, columns = Vocabulary_Importance_Amazon_Train)\n",
    "print (DataFrame_Importance_Amazon_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waktu Training Amazon Feature Importance Only: 55.798s\n"
     ]
    }
   ],
   "source": [
    "Waktu_Training = time()\n",
    "RF_Classifier_Amazon_Importance = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Amazon_Importance.fit(Data_Train_Importance_Amazon, Label_Amazon_Train)\n",
    "print(f\"\\nWaktu Training Amazon Feature Importance Only: {round(time()-Waktu_Training, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waktu prediksi (train): 1.324s\n",
      "waktu prediksi (test): 0.428s\n",
      "\n",
      "Skor Random Forest Train Amazon Feature Importance : 0.8428\n",
      "Skor Random Forest Test Amazon Feature Importance : 0.806\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[3189  561]\n",
      " [ 618 3132]]\n",
      "\n",
      "Accuracy Train:  0.8428\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84      3750\n",
      "           1       0.85      0.84      0.84      3750\n",
      "\n",
      "    accuracy                           0.84      7500\n",
      "   macro avg       0.84      0.84      0.84      7500\n",
      "weighted avg       0.84      0.84      0.84      7500\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[1014  236]\n",
      " [ 249 1001]]\n",
      "\n",
      "Accuracy Test:  0.806\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1250\n",
      "           1       0.81      0.80      0.80      1250\n",
      "\n",
      "    accuracy                           0.81      2500\n",
      "   macro avg       0.81      0.81      0.81      2500\n",
      "weighted avg       0.81      0.81      0.81      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Waktu_Predict_Train = time()\n",
    "Skor_Train_Amazon_FI = RF_Classifier_Amazon_Importance.score(Data_Train_Importance_Amazon, Label_Amazon_Train)\n",
    "print(f\"waktu prediksi (train): {round(time()-Waktu_Predict_Train, 3)}s\")\n",
    "\n",
    "Waktu_Predict_Test = time()\n",
    "Skor_Test_Amazon_FI = RF_Classifier_Amazon_Importance.score(Data_Test_Importance_Amazon, Label_Amazon_Test)\n",
    "print(f\"waktu prediksi (test): {round(time()-Waktu_Predict_Test, 3)}s\")\n",
    "\n",
    "print(\"\\nSkor Random Forest Train Amazon Feature Importance : {}\".format(Skor_Train_Amazon_FI))\n",
    "print(\"Skor Random Forest Test Amazon Feature Importance : {}\".format(Skor_Test_Amazon_FI))\n",
    "\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Amazon_Importance.predict(Data_Train_Importance_Amazon)\n",
    "Confusion_matrix = confusion_matrix(Label_Amazon_Train, RFC_predict)\n",
    "print(Confusion_matrix)\n",
    "print(\"\\nAccuracy Train: \", accuracy_score(Label_Amazon_Train, RFC_predict))\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(Label_Amazon_Train, RFC_predict))\n",
    "\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Amazon_Importance.predict(Data_Test_Importance_Amazon)\n",
    "Confusion_matrix = confusion_matrix(Label_Amazon_Test, RFC_predict)\n",
    "print(Confusion_matrix)\n",
    "print(\"\\nAccuracy Test: \", accuracy_score(Label_Amazon_Test, RFC_predict))\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(Label_Amazon_Test, RFC_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengetahui akurasi dengan hanya mengambil data train dari interseksi antara data yelp dan amazon(Feature imporantace > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_intersection = list(set(Vocabulary_Importance_Amazon) & set (Vocabulary_Train_Yelp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib_venn._common.VennDiagram at 0x1300f268dc8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "venn2(subsets = (len(Vocabulary_Importance_Amazon_Train), len(Vocabulary_Train_Yelp), len(Vocabulary_intersection)), set_labels = ('Vocabulary Amazon fiture importance > 0', 'Vocabulary Yelp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_intersection_yelp = TfidfVectorizer(vocabulary = Vocabulary_intersection, ngram_range=(2,3),analyzer = 'char')\n",
    "vectorizer_intersection_yelp.fit(Clean_Yelp_Sentiment_Train)\n",
    "\n",
    "Vocabulary_Intersection_Train = vectorizer_intersection_yelp.get_feature_names()\n",
    "Data_Train_Intersection = vectorizer_intersection_yelp.transform(Clean_Yelp_Sentiment_Train).toarray()\n",
    "Data_Test_Intersection = vectorizer_intersection_yelp.transform(Clean_Yelp_Sentiment_Test).toarray()\n",
    "\n",
    "# tf = tfidfvectorizer()\n",
    "# tf.fit(train)\n",
    "# trainx = tf.transform(train)\n",
    "# testx = tf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      c i  rno       ash   zi       one       s w       ork  ito  xtr  \\\n",
      "0     0.0  0.0  0.000000  0.0  0.030027  0.000000  0.000000  0.0  0.0   \n",
      "1     0.0  0.0  0.020607  0.0  0.020987  0.000000  0.049182  0.0  0.0   \n",
      "2     0.0  0.0  0.019396  0.0  0.039507  0.019507  0.000000  0.0  0.0   \n",
      "3     0.0  0.0  0.035687  0.0  0.018173  0.017946  0.000000  0.0  0.0   \n",
      "4     0.0  0.0  0.000000  0.0  0.026942  0.026606  0.000000  0.0  0.0   \n",
      "...   ...  ...       ...  ...       ...       ...       ...  ...  ...   \n",
      "7495  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "7496  0.0  0.0  0.000000  0.0  0.021536  0.042534  0.000000  0.0  0.0   \n",
      "7497  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "7498  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "7499  0.0  0.0  0.000000  0.0  0.000000  0.013167  0.000000  0.0  0.0   \n",
      "\n",
      "          ft   ...  dd        xpe       opl  obs        pr  dth  smi  rbo  \\\n",
      "0     0.03764  ...  0.0  0.015252  0.000000  0.0  0.032171  0.0  0.0  0.0   \n",
      "1     0.01973  ...  0.0  0.000000  0.017886  0.0  0.022485  0.0  0.0  0.0   \n",
      "2     0.00000  ...  0.0  0.000000  0.016836  0.0  0.010582  0.0  0.0  0.0   \n",
      "3     0.00000  ...  0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
      "4     0.00000  ...  0.0  0.000000  0.000000  0.0  0.028866  0.0  0.0  0.0   \n",
      "...       ...  ...  ...       ...       ...  ...       ...  ...  ...  ...   \n",
      "7495  0.00000  ...  0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
      "7496  0.00000  ...  0.0  0.000000  0.000000  0.0  0.023074  0.0  0.0  0.0   \n",
      "7497  0.00000  ...  0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
      "7498  0.00000  ...  0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
      "7499  0.00000  ...  0.0  0.000000  0.022728  0.0  0.000000  0.0  0.0  0.0   \n",
      "\n",
      "           reg   b   \n",
      "0     0.000000  0.0  \n",
      "1     0.021966  0.0  \n",
      "2     0.000000  0.0  \n",
      "3     0.000000  0.0  \n",
      "4     0.000000  0.0  \n",
      "...        ...  ...  \n",
      "7495  0.000000  0.0  \n",
      "7496  0.000000  0.0  \n",
      "7497  0.000000  0.0  \n",
      "7498  0.000000  0.0  \n",
      "7499  0.000000  0.0  \n",
      "\n",
      "[7500 rows x 2885 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Intersection_Train = pd.DataFrame(Data_Train_Intersection, columns = Vocabulary_Intersection_Train)\n",
    "print(DataFrame_Intersection_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Akurasi interseksi yelp dan amazon (FI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waktu Training data interseksi Only: 63.098s\n"
     ]
    }
   ],
   "source": [
    "waktu_training_interseksi = time()\n",
    "RF_Classifier_Yelp_intersec = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Yelp_intersec.fit(Data_Train_Intersection, Label_Yelp_Train)\n",
    "print(f\"\\nWaktu Training data interseksi Only: {round(time()-waktu_training_interseksi, 3)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waktu prediksi (train): 1.451s\n",
      "waktu prediksi (test): 0.515s\n",
      "\n",
      "Skor Random Forest Train Interseksi : 0.8750666666666667\n",
      "Skor Random Forest Test Interseksi : 0.8468\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[3251  499]\n",
      " [ 438 3312]]\n",
      "\n",
      "Accuracy Train:  0.8750666666666667\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      3750\n",
      "           1       0.87      0.88      0.88      3750\n",
      "\n",
      "    accuracy                           0.88      7500\n",
      "   macro avg       0.88      0.88      0.88      7500\n",
      "weighted avg       0.88      0.88      0.88      7500\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[1068  182]\n",
      " [ 201 1049]]\n",
      "\n",
      "Accuracy Test:  0.8468\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85      1250\n",
      "           1       0.85      0.84      0.85      1250\n",
      "\n",
      "    accuracy                           0.85      2500\n",
      "   macro avg       0.85      0.85      0.85      2500\n",
      "weighted avg       0.85      0.85      0.85      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Waktu_Predict_Train = time()\n",
    "Skor_Train_Interseksi_Yelp = RF_Classifier_Yelp_intersec.score(Data_Train_Intersection, Label_Yelp_Train)\n",
    "print(f\"waktu prediksi (train): {round(time()-Waktu_Predict_Train, 3)}s\")\n",
    "\n",
    "Waktu_Predict_Test = time()\n",
    "Skor_Test_Interseksi_Yelp = RF_Classifier_Yelp_intersec.score(Data_Test_Intersection, Label_Yelp_Test)\n",
    "print(f\"waktu prediksi (test): {round(time()-Waktu_Predict_Test, 3)}s\")\n",
    "\n",
    "print(\"\\nSkor Random Forest Train Interseksi : {}\".format(Skor_Train_Interseksi_Yelp))\n",
    "print(\"Skor Random Forest Test Interseksi : {}\".format(Skor_Test_Interseksi_Yelp))\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Yelp_intersec.predict(Data_Train_Intersection)\n",
    "Confusion_matrix = confusion_matrix(Label_Yelp_Train, RFC_predict)\n",
    "print(Confusion_matrix)\n",
    "print(\"\\nAccuracy Train: \", accuracy_score(Label_Yelp_Train, RFC_predict))\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(Label_Yelp_Train, RFC_predict))\n",
    "\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Yelp_intersec.predict(Data_Test_Intersection)\n",
    "Confusion_matrix = confusion_matrix(Label_Yelp_Test, RFC_predict)\n",
    "print(Confusion_matrix)\n",
    "print(\"\\nAccuracy Test: \", accuracy_score(Label_Yelp_Test, RFC_predict))\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(Label_Yelp_Test, RFC_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengetahui akurasi dengan hanya mengambil Data Train Yelp yang diseleksi dengan data amazon feature importance > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meseleksi jika terdapat term yang sama pada dictionary yelp dan amazon maka akan di cek apakah term tersebut, \n",
    "# memiliki feature importance > 0, jika tidak maka tidak akan dimasukan untuk data train selanjutnya  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_Seleksi_Yelp = []\n",
    "iterator = 0\n",
    "length = len(Vocabulary_Train_Yelp)\n",
    "\n",
    "while iterator < length : \n",
    "#     jika interseksi dengan amazon dan bukan fitur importance maka vocab tidak dimasukan\n",
    "    if  (Vocabulary_Train_Yelp[iterator] in Vocabulary_Train_Amazon) and (Vocabulary_Train_Yelp[iterator] not in Vocabulary_Importance_Amazon_Train) : \n",
    "        iterator = iterator + 1\n",
    "        continue\n",
    "        \n",
    "    Vocabulary_Seleksi_Yelp.append(Vocabulary_Train_Yelp[iterator])\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_seleksi_yelp = TfidfVectorizer(vocabulary = Vocabulary_Seleksi_Yelp, ngram_range=(2,3),analyzer = 'char')\n",
    "vectorizer_seleksi_yelp.fit(Clean_Yelp_Sentiment_Train)\n",
    "\n",
    "Vocabulary_Seleksi_Yelp_Train = vectorizer_seleksi_yelp.get_feature_names()\n",
    "Data_Train_Seleksi_Yelp = vectorizer_seleksi_yelp.transform(Clean_Yelp_Sentiment_Train).toarray()\n",
    "Data_Test_Seleksi_Yelp = vectorizer_seleksi_yelp.transform(Clean_Yelp_Sentiment_Test).toarray()\n",
    "\n",
    "# tf = tfidfvectorizer()\n",
    "# tf.fit(train)\n",
    "# trainx = tf.transform(train)\n",
    "# testx = tf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             a        a         ab        ac        ad        af   ag   ah  \\\n",
      "0     0.178855  0.050168  0.037623  0.000000  0.017962  0.015069  0.0  0.0   \n",
      "1     0.143564  0.045021  0.013130  0.000000  0.037611  0.000000  0.0  0.0   \n",
      "2     0.164673  0.056559  0.012371  0.047231  0.017719  0.000000  0.0  0.0   \n",
      "3     0.194841  0.026025  0.022770  0.000000  0.000000  0.027360  0.0  0.0   \n",
      "4     0.064192  0.038583  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "...        ...       ...       ...       ...       ...       ...  ...  ...   \n",
      "7495  0.111234  0.033429  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "7496  0.166405  0.046163  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "7497  0.048004  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "7498  0.066243  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "7499  0.174724  0.085925  0.016706  0.000000  0.000000  0.020074  0.0  0.0   \n",
      "\n",
      "       ai        al  ...  zy   zyb  zye  zyl  zyn  zyy   zz  zza  zzc  zzn  \n",
      "0     0.0  0.009734  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.0  0.019205  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.0  0.035347  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "7495  0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7496  0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7497  0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7498  0.0  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7499  0.0  0.025934  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[7500 rows x 4314 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Seleksi = pd.DataFrame(Data_Train_Seleksi_Yelp, columns = Vocabulary_Seleksi_Yelp_Train)\n",
    "print (DataFrame_Seleksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waktu Training data seleksi: 66.868s\n"
     ]
    }
   ],
   "source": [
    "waktu_training_seleksi_yelp = time()\n",
    "RF_Classifier_Yelp_Seleksi = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Yelp_Seleksi.fit(Data_Train_Seleksi_Yelp, Label_Yelp_Train)\n",
    "print(f\"\\nWaktu Training data seleksi: {round(time()-waktu_training_seleksi_yelp, 3)}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waktu prediksi (train): 1.292s\n",
      "waktu prediksi (test): 0.434s\n",
      "\n",
      "Skor Random Forest Train Seleksi : 0.8750666666666667\n",
      "Skor Random Forest Test Seleksi : 0.8444\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[3224  526]\n",
      " [ 411 3339]]\n",
      "\n",
      "Accuracy Test:  0.8750666666666667\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87      3750\n",
      "           1       0.86      0.89      0.88      3750\n",
      "\n",
      "    accuracy                           0.88      7500\n",
      "   macro avg       0.88      0.88      0.88      7500\n",
      "weighted avg       0.88      0.88      0.88      7500\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "[[1058  192]\n",
      " [ 197 1053]]\n",
      "\n",
      "Accuracy TEST:  0.8444\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84      1250\n",
      "           1       0.85      0.84      0.84      1250\n",
      "\n",
      "    accuracy                           0.84      2500\n",
      "   macro avg       0.84      0.84      0.84      2500\n",
      "weighted avg       0.84      0.84      0.84      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Waktu_Predict_Train = time()\n",
    "Skor_Train_Seleksi_Yelp = RF_Classifier_Yelp_Seleksi.score(Data_Train_Seleksi_Yelp, Label_Yelp_Train)\n",
    "print(f\"waktu prediksi (train): {round(time()-Waktu_Predict_Train, 3)}s\")\n",
    "\n",
    "Waktu_Predict_Test = time()\n",
    "Skor_Test_Seleksi_Yelp = RF_Classifier_Yelp_Seleksi.score(Data_Test_Seleksi_Yelp, Label_Yelp_Test)\n",
    "print(f\"waktu prediksi (test): {round(time()-Waktu_Predict_Test, 3)}s\")\n",
    "\n",
    "print(\"\\nSkor Random Forest Train Seleksi : {}\".format(Skor_Train_Seleksi_Yelp))\n",
    "print(\"Skor Random Forest Test Seleksi : {}\".format(Skor_Test_Seleksi_Yelp))\n",
    "\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Yelp_Seleksi.predict(Data_Train_Seleksi_Yelp)\n",
    "Confusion_matrix = confusion_matrix(Label_Yelp_Train, RFC_predict)\n",
    "print(Confusion_matrix)\n",
    "print(\"\\nAccuracy Test: \", accuracy_score(Label_Yelp_Train, RFC_predict))\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(Label_Yelp_Train, RFC_predict))\n",
    "\n",
    "print(\"----------------------------------------------------\\n\\n\")\n",
    "RFC_predict = RF_Classifier_Yelp_Seleksi.predict(Data_Test_Seleksi_Yelp)\n",
    "Confusion_matrix = confusion_matrix(Label_Yelp_Test, RFC_predict)\n",
    "print(Confusion_matrix)\n",
    "print(\"\\nAccuracy TEST: \", accuracy_score(Label_Yelp_Test, RFC_predict))\n",
    "print(\"\\n\")\n",
    "print(metrics.classification_report(Label_Yelp_Test, RFC_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RF_seleksi.joblib']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(RF_Classifier_Yelp_Seleksi, 'RF_seleksi.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectroizer_seleksi.joblib']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(vectorizer_seleksi_yelp, 'vectroizer_seleksi.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_tes = pd.read_csv('tes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentiment\n",
      "0  Buyer beware This is a self-published book, an...\n",
      "1  The Worst! A complete waste of time. Typograph...\n",
      "2  Oh please I guess you have to be a romance nov...\n",
      "3  Awful beyond belief! I feel I have to write to...\n",
      "4  Another Abysmal Digital Copy Rather than scrat...\n"
     ]
    }
   ],
   "source": [
    "print(data_train_tes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfprint = pd.DataFrame()\n",
    "dfprint['COMMENT'] = data_train_tes.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_baru = dfprint['COMMENT'].astype(str)    \n",
    "text_baru = text_baru.apply(lambda x: x.lower()) #Lower Case\n",
    "text_baru = text_baru.apply(lambda x: re.sub(r\"\\d\", \"\", x)) #Remove Number    \n",
    "text_baru = text_baru.apply(lambda x: x.translate(str.maketrans('','',string.punctuation))) #punctuation  \n",
    "text_baru = text_baru.apply(lambda x: \" \".join(re.findall(\"[a-zA-Z]+\", x)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buyer beware this is a selfpublished book and if you want to know whyread a few paragraphs those  star reviews must have been written by ms haddons family and friendsor perhaps by herself i cant imagine anyone reading the whole thingi spent an evening with the book and a friend and we were in hysterics reading bits and pieces of it to one another it is most definitely bad enough to be entered into some kind of a worst book contest i cant believe amazon even sells this kind of thing maybe i can offer them my th grade term paper on to kill a mockingbirda book i am quite sure ms haddon never heard of anyway unless you are in a mood to send a book to someone as a jokestay far far away from this one\n"
     ]
    }
   ],
   "source": [
    "print(text_baru[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buyer beware this is a selfpublished book and if you want to know whyread a few paragraphs those star reviews must have been written by ms haddons family and friendsor perhaps by herself i cant imagine anyone reading the whole thingi spent an evening with the book and a friend and we were in hysterics reading bits and pieces of it to one another it is most definitely bad enough to be entered into some kind of a worst book contest i cant believe amazon even sells this kind of thing maybe i can offer them my th grade term paper on to kill a mockingbirda book i am quite sure ms haddon never heard of anyway unless you are in a mood to send a book to someone as a jokestay far far away from this one\n"
     ]
    }
   ],
   "source": [
    "print (text_baru[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buyer beware This is a self-published book, and if you want to know why--read a few paragraphs! Those 5 star reviews must have been written by Ms. Haddon's family and friends--or perhaps, by herself! I can't imagine anyone reading the whole thing--I spent an evening with the book and a friend and we were in hysterics reading bits and pieces of it to one another. It is most definitely bad enough to be entered into some kind of a \"worst book\" contest. I can't believe Amazon even sells this kind of thing. Maybe I can offer them my 8th grade term paper on \"To Kill a Mockingbird\"--a book I am quite sure Ms. Haddon never heard of. Anyway, unless you are in a mood to send a book to someone as a joke---stay far, far away from this one!\n"
     ]
    }
   ],
   "source": [
    "print(data_train_tes.sentiment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \"``\".join([str(i) for i in data_train_tes.columns.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n"
     ]
    }
   ],
   "source": [
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buyer beware This is a self-published book, and if you want to know why--read a few paragraphs! Those 5 star reviews must have been written by Ms. Haddon's family and friends--or perhaps, by herself! I can't imagine anyone reading the whole thing--I spent an evening with the book and a friend and we were in hysterics reading bits and pieces of it to one another. It is most definitely bad enough to be entered into some kind of a \"worst book\" contest. I can't believe Amazon even sells this kind of thing. Maybe I can offer them my 8th grade term paper on \"To Kill a Mockingbird\"--a book I am quite sure Ms. Haddon never heard of. Anyway, unless you are in a mood to send a book to someone as a joke---stay far, far away from this one!\n"
     ]
    }
   ],
   "source": [
    "print(data_train_tes[cols][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
