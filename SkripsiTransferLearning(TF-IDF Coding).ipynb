{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKRIPSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk import ngrams\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, validation_curve,RandomizedSearchCV\n",
    "\n",
    "np.random.seed(0)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "poster_Stemmer = nltk.PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baca file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baca csv\n",
    "data_amazon = pd.read_csv('Amazon_dataset.csv')\n",
    "data_yelp = pd.read_csv('Yelp_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen\n",
       "0      0  Buyer beware This is a self-published book, an...\n",
       "1      0  The Worst! A complete waste of time. Typograph...\n",
       "2      0  Oh please I guess you have to be a romance nov...\n",
       "3      0  Awful beyond belief! I feel I have to write to...\n",
       "4      0  Another Abysmal Digital Copy Rather than scrat..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen\n",
       "0      0  I don't know what Dr. Goldberg was like before...\n",
       "1      0  I'm writing this review to give you a heads up...\n",
       "2      0  Owning a driving range inside the city limits ...\n",
       "3      0  This place is absolute garbage...  Half of the...\n",
       "4      0  Used to go there for tires, brakes, etc.  Thei..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing ke lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_Preprocessing_Amazon = data_amazon\n",
    "data_Lowercase_Amazon = []\n",
    "\n",
    "data_Preprocessing_Yelp = data_yelp\n",
    "data_Lowercase_Yelp = []\n",
    "\n",
    "while iterator < len(data_amazon) :\n",
    "    data_Lowercase_Amazon.append(data_amazon.Sentimen[iterator].lower())\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_yelp) :\n",
    "    data_Lowercase_Yelp.append(data_yelp.Sentimen[iterator].lower())\n",
    "    iterator = iterator + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \n",
       "0  buyer beware this is a self-published book, an...  \n",
       "1  the worst! a complete waste of time. typograph...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief! i feel i have to write to...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon['Lowercase'] = data_Lowercase_Amazon\n",
    "data_Preprocessing_Amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \n",
       "0  i don't know what dr. goldberg was like before...  \n",
       "1  i'm writing this review to give you a heads up...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage...  half of the...  \n",
       "4  used to go there for tires, brakes, etc.  thei...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp['Lowercase'] = data_Lowercase_Yelp\n",
    "data_Preprocessing_Yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghilangkan angka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_RemoveNumber_Amazon = []\n",
    "\n",
    "data_RemoveNumber_Yelp = []\n",
    "\n",
    "while iterator < len(data_Preprocessing_Amazon) :\n",
    "    data_RemoveNumber_Amazon.append(re.sub(r\"\\d+\", \"\",data_Preprocessing_Amazon.Lowercase[iterator]))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_Preprocessing_Yelp) :\n",
    "    data_RemoveNumber_Yelp.append(re.sub(r\"\\d+\", \"\",data_Preprocessing_Yelp.Lowercase[iterator]))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                        RemoveNumber  \n",
       "0  buyer beware this is a self-published book, an...  \n",
       "1  the worst! a complete waste of time. typograph...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief! i feel i have to write to...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon['RemoveNumber'] = data_RemoveNumber_Amazon\n",
    "data_Preprocessing_Amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                        RemoveNumber  \n",
       "0  i don't know what dr. goldberg was like before...  \n",
       "1  i'm writing this review to give you a heads up...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage...  half of the...  \n",
       "4  used to go there for tires, brakes, etc.  thei...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp['RemoveNumber'] = data_RemoveNumber_Yelp\n",
    "data_Preprocessing_Yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghilangkan tanda baca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "data_RemovePunctuation_Amazon = []\n",
    "\n",
    "data_RemovePunctuation_Yelp = []\n",
    "\n",
    "while iterator < len(data_Preprocessing_Amazon) :\n",
    "    data_RemovePunctuation_Amazon.append(data_Preprocessing_Amazon.RemoveNumber[iterator].translate(str.maketrans('','', string.punctuation)))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_Preprocessing_Yelp) :\n",
    "    data_RemovePunctuation_Yelp.append(data_Preprocessing_Yelp.RemoveNumber[iterator].translate(str.maketrans('','', string.punctuation)))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a selfpublished book and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst a complete waste of time typographic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief i feel i have to write to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                   RemovePunctuation  \n",
       "0  buyer beware this is a selfpublished book and ...  \n",
       "1  the worst a complete waste of time typographic...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief i feel i have to write to ...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon['RemovePunctuation'] = data_RemovePunctuation_Amazon\n",
    "data_Preprocessing_Amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i dont know what dr goldberg was like before  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>im writing this review to give you a heads up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage  half of the te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires brakes etc  their p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                   RemovePunctuation  \n",
       "0  i dont know what dr goldberg was like before  ...  \n",
       "1  im writing this review to give you a heads up ...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage  half of the te...  \n",
       "4  used to go there for tires brakes etc  their p...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp['RemovePunctuation'] = data_RemovePunctuation_Yelp\n",
    "data_Preprocessing_Yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghilangkan Non alfabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "\n",
    "data_Regex_alpabet_only_Amazon = []\n",
    "\n",
    "data_Regex_alpabet_only_Yelp = []\n",
    "\n",
    "\n",
    "while iterator < len(data_Preprocessing_Amazon) :\n",
    "    data_Regex_alpabet_only_Amazon.append(\" \".join(re.findall(\"[a-zA-Z]+\", data_Preprocessing_Amazon.RemovePunctuation[iterator])))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "while iterator < len(data_Preprocessing_Yelp) :\n",
    "    data_Regex_alpabet_only_Yelp.append(\" \".join(re.findall(r\"[a-zA-Z]+\", data_Preprocessing_Yelp.RemovePunctuation[iterator])))\n",
    "    iterator = iterator + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "      <th>Regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a self-published book, an...</td>\n",
       "      <td>buyer beware this is a selfpublished book and ...</td>\n",
       "      <td>buyer beware this is a selfpublished book and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst! a complete waste of time. typograph...</td>\n",
       "      <td>the worst a complete waste of time typographic...</td>\n",
       "      <td>the worst a complete waste of time typographic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh please I guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "      <td>oh please i guess you have to be a romance nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Awful beyond belief! I feel I have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief! i feel i have to write to...</td>\n",
       "      <td>awful beyond belief i feel i have to write to ...</td>\n",
       "      <td>awful beyond belief i feel i have to write to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Another Abysmal Digital Copy Rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "      <td>another abysmal digital copy rather than scrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  Buyer beware This is a self-published book, an...   \n",
       "1      0  The Worst! A complete waste of time. Typograph...   \n",
       "2      0  Oh please I guess you have to be a romance nov...   \n",
       "3      0  Awful beyond belief! I feel I have to write to...   \n",
       "4      0  Another Abysmal Digital Copy Rather than scrat...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  buyer beware this is a self-published book, an...   \n",
       "1  the worst! a complete waste of time. typograph...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief! i feel i have to write to...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                   RemovePunctuation  \\\n",
       "0  buyer beware this is a selfpublished book and ...   \n",
       "1  the worst a complete waste of time typographic...   \n",
       "2  oh please i guess you have to be a romance nov...   \n",
       "3  awful beyond belief i feel i have to write to ...   \n",
       "4  another abysmal digital copy rather than scrat...   \n",
       "\n",
       "                                               Regex  \n",
       "0  buyer beware this is a selfpublished book and ...  \n",
       "1  the worst a complete waste of time typographic...  \n",
       "2  oh please i guess you have to be a romance nov...  \n",
       "3  awful beyond belief i feel i have to write to ...  \n",
       "4  another abysmal digital copy rather than scrat...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Amazon['Regex'] = data_Regex_alpabet_only_Amazon\n",
    "data_Preprocessing_Amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>RemoveNumber</th>\n",
       "      <th>RemovePunctuation</th>\n",
       "      <th>Regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i don't know what dr. goldberg was like before...</td>\n",
       "      <td>i dont know what dr goldberg was like before  ...</td>\n",
       "      <td>i dont know what dr goldberg was like before m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>i'm writing this review to give you a heads up...</td>\n",
       "      <td>im writing this review to give you a heads up ...</td>\n",
       "      <td>im writing this review to give you a heads up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "      <td>owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is absolute garbage...  Half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage...  half of the...</td>\n",
       "      <td>this place is absolute garbage  half of the te...</td>\n",
       "      <td>this place is absolute garbage half of the tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Used to go there for tires, brakes, etc.  Thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires, brakes, etc.  thei...</td>\n",
       "      <td>used to go there for tires brakes etc  their p...</td>\n",
       "      <td>used to go there for tires brakes etc their pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Sentimen  \\\n",
       "0      0  I don't know what Dr. Goldberg was like before...   \n",
       "1      0  I'm writing this review to give you a heads up...   \n",
       "2      0  Owning a driving range inside the city limits ...   \n",
       "3      0  This place is absolute garbage...  Half of the...   \n",
       "4      0  Used to go there for tires, brakes, etc.  Thei...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                        RemoveNumber  \\\n",
       "0  i don't know what dr. goldberg was like before...   \n",
       "1  i'm writing this review to give you a heads up...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage...  half of the...   \n",
       "4  used to go there for tires, brakes, etc.  thei...   \n",
       "\n",
       "                                   RemovePunctuation  \\\n",
       "0  i dont know what dr goldberg was like before  ...   \n",
       "1  im writing this review to give you a heads up ...   \n",
       "2  owning a driving range inside the city limits ...   \n",
       "3  this place is absolute garbage  half of the te...   \n",
       "4  used to go there for tires brakes etc  their p...   \n",
       "\n",
       "                                               Regex  \n",
       "0  i dont know what dr goldberg was like before m...  \n",
       "1  im writing this review to give you a heads up ...  \n",
       "2  owning a driving range inside the city limits ...  \n",
       "3  this place is absolute garbage half of the tee...  \n",
       "4  used to go there for tires brakes etc their pr...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Preprocessing_Yelp['Regex'] = data_Regex_alpabet_only_Yelp\n",
    "data_Preprocessing_Yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_Amazon_Sentiment = data_Preprocessing_Amazon['Regex']\n",
    "Clean_Yelp_Sentiment = data_Preprocessing_Yelp['Regex']\n",
    "Label_Amazon = data_Preprocessing_Amazon['Label']\n",
    "Label_Yelp = data_Preprocessing_Yelp['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram (bigram dan trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "Vocabulary_Amazon = []\n",
    "ngram_amazon = []\n",
    "temporary = []\n",
    "\n",
    "while iterator < len(Clean_Amazon_Sentiment) :\n",
    "    ngram = 2\n",
    "    sentence = Clean_Amazon_Sentiment[iterator]\n",
    "    vocab = [sentence[i:i+ngram] for i in range(len(sentence)-ngram+1)]\n",
    "    temp = vocab\n",
    "\n",
    "    iterator2 = 0\n",
    "    while iterator2 < len (vocab):\n",
    "        if(vocab[iterator2] not in Vocabulary_Amazon) :\n",
    "            Vocabulary_Amazon.append(vocab[iterator2])\n",
    "        iterator2 = iterator2 + 1\n",
    "    \n",
    "    ngram = 3\n",
    "    vocab = [sentence[i:i+ngram] for i in range(len(sentence)-ngram+1)]\n",
    "    temp = temp + vocab\n",
    "    ngram_amazon.append(temp)\n",
    "    iterator2 = 0\n",
    "    while iterator2 < len (vocab):\n",
    "        if(vocab[iterator2] not in Vocabulary_Amazon) :\n",
    "            Vocabulary_Amazon.append(vocab[iterator2])\n",
    "        iterator2 = iterator2 + 1\n",
    "        \n",
    "    iterator = iterator + 1\n",
    "    vocab = None\n",
    "    del vocab\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "Vocabulary_Yelp = []\n",
    "ngram_yelp = []\n",
    "temporary = []\n",
    "\n",
    "while iterator < len(Clean_Yelp_Sentiment) :\n",
    "    ngram = 2\n",
    "    sentence = Clean_Yelp_Sentiment[iterator]\n",
    "    \n",
    "    vocab = [sentence[i:i+ngram] for i in range(len(sentence)-ngram+1)]\n",
    "  \n",
    "    temp = vocab\n",
    "\n",
    "    iterator2 = 0\n",
    "    while iterator2 < len (vocab):\n",
    "        if(vocab[iterator2] not in Vocabulary_Yelp) :\n",
    "            Vocabulary_Yelp.append(vocab[iterator2])\n",
    "        iterator2 = iterator2 + 1\n",
    "    \n",
    "    ngram = 3\n",
    "    vocab = [sentence[i:i+ngram] for i in range(len(sentence)-ngram+1)]\n",
    "    temp = temp + vocab\n",
    "    ngram_yelp.append(temp)\n",
    "    iterator2 = 0\n",
    "    while iterator2 < len (vocab):\n",
    "        if(vocab[iterator2] not in Vocabulary_Yelp) :\n",
    "            Vocabulary_Yelp.append(vocab[iterator2])\n",
    "        iterator2 = iterator2 + 1\n",
    "        \n",
    "    iterator = iterator + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Me inisialisasi jumlah frekuensi Gram di Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordDictionaryCount_Amazon = []\n",
    "WordDictionaryCount_Yelp = []\n",
    "\n",
    "iterator = 0\n",
    "while iterator < len(Clean_Amazon_Sentiment):\n",
    "    WordDictionaryCount_Amazon.append(dict.fromkeys(Vocabulary_Amazon, 0))\n",
    "    iterator = iterator + 1\n",
    "    \n",
    "iterator = 0\n",
    "while iterator < len(Clean_Yelp_Sentiment):\n",
    "    WordDictionaryCount_Yelp.append(dict.fromkeys(Vocabulary_Yelp, 0))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "while iterator < len(Clean_Amazon_Sentiment) :\n",
    "    for gram in ngram_amazon[iterator] :\n",
    "        WordDictionaryCount_Amazon[iterator][gram] += 1\n",
    "    iterator = iterator + 1\n",
    "    \n",
    "iterator = 0\n",
    "while iterator < len(Clean_Yelp_Sentiment) :\n",
    "    for gram in ngram_yelp[iterator] :\n",
    "        WordDictionaryCount_Yelp[iterator][gram] += 1\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bu</th>\n",
       "      <th>uy</th>\n",
       "      <th>ye</th>\n",
       "      <th>er</th>\n",
       "      <th>r</th>\n",
       "      <th>b</th>\n",
       "      <th>be</th>\n",
       "      <th>ew</th>\n",
       "      <th>wa</th>\n",
       "      <th>ar</th>\n",
       "      <th>...</th>\n",
       "      <th>hue</th>\n",
       "      <th>wrh</th>\n",
       "      <th>igf</th>\n",
       "      <th>tnb</th>\n",
       "      <th>sgn</th>\n",
       "      <th>gnr</th>\n",
       "      <th>nr</th>\n",
       "      <th>ydl</th>\n",
       "      <th>yov</th>\n",
       "      <th>jae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 9905 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bu  uy  ye  er  r    b  be  ew  wa  ar  ...  hue  wrh  igf  tnb  sgn  gnr  \\\n",
       "0   1   1   1  11   9  13   5   3   4   7  ...    0    0    0    0    0    0   \n",
       "1   0   0   0   2   5   1   0   0   1   2  ...    0    0    0    0    0    0   \n",
       "\n",
       "   nr   ydl  yov  jae  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "\n",
       "[2 rows x 9905 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([WordDictionaryCount_Amazon[0],WordDictionaryCount_Amazon[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>d</th>\n",
       "      <th>do</th>\n",
       "      <th>on</th>\n",
       "      <th>nt</th>\n",
       "      <th>t</th>\n",
       "      <th>k</th>\n",
       "      <th>kn</th>\n",
       "      <th>no</th>\n",
       "      <th>ow</th>\n",
       "      <th>...</th>\n",
       "      <th>qt</th>\n",
       "      <th>qt</th>\n",
       "      <th>lny</th>\n",
       "      <th>fep</th>\n",
       "      <th>cpn</th>\n",
       "      <th>mds</th>\n",
       "      <th>wfs</th>\n",
       "      <th>itv</th>\n",
       "      <th>agb</th>\n",
       "      <th>ej</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 9856 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   i    d  do  on  nt  t    k  kn  no  ow  ...   qt  qt   lny  fep  cpn  mds  \\\n",
       "0   4  11   6  13   7  19   1   1   5   1  ...    0    0    0    0    0    0   \n",
       "1  10   7   6  10  13  21   1   1   1   1  ...    0    0    0    0    0    0   \n",
       "\n",
       "   wfs  itv  agb   ej  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "\n",
       "[2 rows x 9856 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([WordDictionaryCount_Yelp[0],WordDictionaryCount_Yelp[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung nilai TF pada setiap data Amazon dan Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, ngram):\n",
    "    tfDict = {}\n",
    "    ngramLength = len(ngram)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(ngramLength)\n",
    "    return tfDict\n",
    "\n",
    "Tf_Sentimen_Amazon = []\n",
    "Tf_Sentimen_Yelp = []\n",
    "\n",
    "iterator = 0\n",
    "while iterator < len(WordDictionaryCount_Amazon):\n",
    "    Tf_Sentimen_Amazon.append(computeTF(WordDictionaryCount_Amazon[iterator], ngram_amazon[iterator]))\n",
    "    iterator = iterator + 1\n",
    "    \n",
    "iterator = 0\n",
    "while iterator < len(WordDictionaryCount_Yelp):\n",
    "    Tf_Sentimen_Yelp.append(computeTF(WordDictionaryCount_Yelp[iterator], ngram_yelp[iterator]))\n",
    "    iterator = iterator + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung nilai IDF pada setiap data Amazon dan Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def computeIDF(WordDict):\n",
    "    idfDict = {}\n",
    "    N = len(WordDict)\n",
    "    \n",
    "    idfDict = dict.fromkeys(WordDict[0].keys(), 0)\n",
    "    for doc in WordDict:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict\n",
    "\n",
    "IDF_Amazon = computeIDF(WordDictionaryCount_Amazon)\n",
    "IDF_Yelp = computeIDF(WordDictionaryCount_Yelp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung nilai TF-IDF pada setiap data Amazon dan Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(Tf_Sentimen_Amazon, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in Tf_Sentimen_Amazon.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf\n",
    "\n",
    "\n",
    "TF_IDF_Amazon = []\n",
    "iterator = 0\n",
    "while iterator < len(WordDictionaryCount_Amazon):\n",
    "    TF_IDF_Amazon.append(computeTFIDF(Tf_Sentimen_Amazon[iterator], IDF_Amazon))\n",
    "    iterator = iterator + 1\n",
    "    \n",
    "TF_IDF_Yelp = []\n",
    "iterator = 0\n",
    "while iterator < len(WordDictionaryCount_Yelp):\n",
    "    TF_IDF_Yelp.append(computeTFIDF(Tf_Sentimen_Yelp[iterator], IDF_Yelp))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menampung nilai TF-IDF pada variabel Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer_Amazon = []\n",
    "iterator  = 0\n",
    "while iterator < len(TF_IDF_Amazon):\n",
    "    Vectorizer_Amazon.append(list(TF_IDF_Amazon[iterator].values()))\n",
    "    iterator = iterator + 1\n",
    "    \n",
    "Vectorizer_Yelp = []\n",
    "iterator  = 0\n",
    "while iterator < len(TF_IDF_Yelp):\n",
    "    Vectorizer_Yelp.append(list(TF_IDF_Yelp[iterator].values()))\n",
    "    iterator = iterator + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frame Vectorizer Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            bu        uy        ye        er        r          b        be  \\\n",
      "0     0.000193  0.000555  0.000441  0.000186  0.000254  0.000318  0.000603   \n",
      "1     0.000000  0.000000  0.000000  0.000115  0.000479  0.000083  0.000000   \n",
      "2     0.000291  0.000000  0.000000  0.000204  0.000255  0.000257  0.000908   \n",
      "3     0.000000  0.000000  0.000000  0.000194  0.000442  0.000255  0.000757   \n",
      "4     0.000000  0.000000  0.000000  0.000147  0.000266  0.000142  0.000525   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  0.000358  0.001029  0.000000  0.000031  0.000105  0.000136  0.000224   \n",
      "9996  0.000446  0.001281  0.000509  0.000176  0.000130  0.000198  0.000418   \n",
      "9997  0.000000  0.000000  0.001454  0.000000  0.000093  0.000161  0.000000   \n",
      "9998  0.001120  0.000000  0.000000  0.000245  0.000164  0.000213  0.000350   \n",
      "9999  0.000000  0.000000  0.000000  0.000212  0.000354  0.000077  0.000000   \n",
      "\n",
      "            ew        wa        ar  ...  hue  wrh  igf  tnb  sgn  gnr  nr   \\\n",
      "0     0.001135  0.000494  0.000523  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1     0.000000  0.000419  0.000507  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2     0.001138  0.000743  0.000225  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3     0.001185  0.000516  0.000156  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4     0.000274  0.000179  0.000705  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "9995  0.001404  0.000000  0.000277  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9996  0.000437  0.000855  0.000259  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9997  0.000000  0.000407  0.000739  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9998  0.000000  0.000716  0.000217  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9999  0.000000  0.000774  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      ydl  yov  jae  \n",
      "0     0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.0  \n",
      "...   ...  ...  ...  \n",
      "9995  0.0  0.0  0.0  \n",
      "9996  0.0  0.0  0.0  \n",
      "9997  0.0  0.0  0.0  \n",
      "9998  0.0  0.0  0.0  \n",
      "9999  0.0  0.0  0.0  \n",
      "\n",
      "[10000 rows x 9905 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Amazon = pd.DataFrame(Vectorizer_Amazon, columns = Vocabulary_Amazon)\n",
    "print (DataFrame_Amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Vectorizer Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            i          d        do        on        nt        t          k  \\\n",
      "0     0.000184  0.000388  0.000692  0.000343  0.000248  0.000095  0.000200   \n",
      "1     0.000506  0.000272  0.000761  0.000290  0.000508  0.000116  0.000220   \n",
      "2     0.000187  0.000216  0.000352  0.000376  0.000362  0.000143  0.000000   \n",
      "3     0.000096  0.000443  0.000483  0.000276  0.000149  0.000178  0.000000   \n",
      "4     0.000000  0.000129  0.000421  0.000289  0.000778  0.000201  0.000000   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  0.000395  0.000101  0.000000  0.000151  0.000102  0.000043  0.000572   \n",
      "9996  0.000000  0.000000  0.000000  0.000000  0.000000  0.000204  0.000000   \n",
      "9997  0.001175  0.000129  0.000000  0.000096  0.000130  0.000146  0.000729   \n",
      "9998  0.000217  0.000200  0.000218  0.000225  0.000604  0.000080  0.000189   \n",
      "9999  0.000933  0.000119  0.000390  0.000089  0.000240  0.000085  0.000000   \n",
      "\n",
      "            kn        no        ow  ...   qt  qt   lny  fep  cpn  mds  wfs  \\\n",
      "0     0.000294  0.000337  0.000101  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1     0.000323  0.000074  0.000111  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2     0.000000  0.000275  0.000411  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3     0.000000  0.000282  0.000211  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4     0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "9995  0.000000  0.000000  0.000289  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9996  0.000000  0.000000  0.001030  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9997  0.001073  0.000246  0.000368  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9998  0.000556  0.000127  0.000191  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9999  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      itv  agb        ej  \n",
      "0     0.0  0.0  0.000000  \n",
      "1     0.0  0.0  0.000000  \n",
      "2     0.0  0.0  0.000000  \n",
      "3     0.0  0.0  0.000000  \n",
      "4     0.0  0.0  0.000000  \n",
      "...   ...  ...       ...  \n",
      "9995  0.0  0.0  0.000000  \n",
      "9996  0.0  0.0  0.000000  \n",
      "9997  0.0  0.0  0.000000  \n",
      "9998  0.0  0.0  0.001707  \n",
      "9999  0.0  0.0  0.000000  \n",
      "\n",
      "[10000 rows x 9856 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Yelp = pd.DataFrame(Vectorizer_Yelp, columns = Vocabulary_Yelp)\n",
    "print (DataFrame_Yelp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jumlah data label positif dan negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data positif negatif amazon\n",
      "1    5000\n",
      "0    5000\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "\n",
      "Data positif negatif yelp\n",
      "1    5000\n",
      "0    5000\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Data positif negatif amazon\")\n",
    "DataFrame_Label = pd.DataFrame(Label_Amazon)\n",
    "print(DataFrame_Label['Label'].value_counts())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Data positif negatif yelp\")\n",
    "DataFrame_Label = pd.DataFrame(Label_Yelp)\n",
    "print(DataFrame_Label['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split data amazon dan yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_amazon, data_test_amazon, label_train_amazon, label_test_amazon = train_test_split((Vectorizer_Amazon), Label_Amazon, random_state = 0)\n",
    "data_train_yelp, data_test_yelp, label_train_yelp, label_test_yelp = train_test_split((Vectorizer_Yelp), Label_Yelp, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon data\n",
      "data train shape : (7500, 9905)\n",
      "data test shape : (2500, 9905)\n",
      "label train shape : (7500,)\n",
      "label test shape : (2500,)\n",
      "\n",
      "Yelp data\n",
      "data train shape : (7500, 9856)\n",
      "data test shape : (2500, 9856)\n",
      "label train shape : (7500,)\n",
      "label test shape : (2500,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Amazon data\")\n",
    "data_train_amazon = np.array(data_train_amazon)\n",
    "data_train_yelp = np.array(data_train_yelp)\n",
    "data_test_amazon = np.array(data_test_amazon)\n",
    "data_test_yelp = np.array(data_test_yelp)\n",
    "\n",
    "label_train_amazon = np.array(label_train_amazon)\n",
    "label_train_yelp = np.array(label_train_yelp)\n",
    "label_test_amazon = np.array(label_test_amazon)\n",
    "label_test_yelp = np.array(label_test_yelp)\n",
    "\n",
    "print(\"data train shape : {}\".format(data_train_amazon.shape))\n",
    "print(\"data test shape : {}\".format(data_test_amazon.shape))\n",
    "print(\"label train shape : {}\".format(label_train_amazon.shape))\n",
    "print(\"label test shape : {}\".format(label_test_amazon.shape))\n",
    "\n",
    "print(\"\\nYelp data\")\n",
    "print(\"data train shape : {}\".format(data_train_yelp.shape))\n",
    "print(\"data test shape : {}\".format(data_test_yelp.shape))\n",
    "print(\"label train shape : {}\".format(label_train_yelp.shape))\n",
    "print(\"label test shape : {}\".format(label_test_yelp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# dr = PCA(n_components = 300)\n",
    "# dr.fit(data_train_amazon)\n",
    "# data_train_amazon = dr.transform(data_train_amazon)\n",
    "# data_test_amazon = dr.transform(data_test_amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skor Akurasi Amazon dan Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skor RF_Amazon: 0.8116\n",
      "skor RF_Yelp: 0.8304\n"
     ]
    }
   ],
   "source": [
    "RF_Classifier_Amazon = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Amazon.fit(data_train_amazon, label_train_amazon)\n",
    "print(\"skor RF_Amazon: {}\".format(RF_Classifier_Amazon.score(data_test_amazon, label_test_amazon)))\n",
    "\n",
    "RF_Classifier_Yelp = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Yelp.fit(data_train_yelp, label_train_yelp)\n",
    "print(\"skor RF_Yelp: {}\".format(RF_Classifier_Yelp.score(data_test_yelp, label_test_yelp)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mencari Fitur Importance > 0 dari Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_Importance_Amazon = []\n",
    "iterator = 0\n",
    "length = len (Vocabulary_Amazon)\n",
    "\n",
    "while iterator < length : \n",
    "    if RF_Classifier_Amazon.feature_importances_[iterator] > 0 :\n",
    "        Vocabulary_Importance_Amazon.append(Vocabulary_Amazon[iterator])\n",
    "       \n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengetahui Akurasi jika diterapkan Transfer learning Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Jika diterapkan data interseksi antara Vocabulary_Amazon (fi > 0) dan Vocabulary Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_Intersection = list(set(Vocabulary_Importance_Amazon) & set (Vocabulary_Yelp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "WordDictionaryCount_Intersection = []\n",
    "\n",
    "iterator = 0\n",
    "while iterator < len(ngram_yelp):\n",
    "    WordDictionaryCount_Intersection.append(dict.fromkeys(Vocabulary_Intersection, 0))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "while iterator < len(ngram_yelp) :\n",
    "    for gram in ngram_yelp[iterator] :\n",
    "        if gram in Vocabulary_Intersection :\n",
    "            WordDictionaryCount_Intersection[iterator][gram] += 1\n",
    "    iterator = iterator + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "TF_Intersection = []\n",
    "while iterator < len(WordDictionaryCount_Intersection):\n",
    "    TF_Intersection.append(computeTF(WordDictionaryCount_Intersection[iterator], ngram_yelp[iterator]))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "IDF_Intersection = computeIDF(WordDictionaryCount_Intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_Intersection = []\n",
    "iterator = 0\n",
    "while iterator < len(WordDictionaryCount_Intersection):\n",
    "    TF_IDF_Intersection.append(computeTFIDF(TF_Intersection[iterator], IDF_Amazon))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer_Intersection = []\n",
    "iterator  = 0\n",
    "while iterator < len(TF_IDF_Intersection):\n",
    "    Vectorizer_Intersection.append(list(TF_IDF_Intersection[iterator].values()))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             d       nto  ago       ric  noy        lo  anu       owe  \\\n",
      "0     0.000495  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "1     0.000347  0.000000  0.0  0.000413  0.0  0.000357  0.0  0.000000   \n",
      "2     0.000275  0.000467  0.0  0.000000  0.0  0.000110  0.0  0.000000   \n",
      "3     0.000566  0.000960  0.0  0.000000  0.0  0.000453  0.0  0.000000   \n",
      "4     0.000164  0.000000  0.0  0.001370  0.0  0.001186  0.0  0.000000   \n",
      "...        ...       ...  ...       ...  ...       ...  ...       ...   \n",
      "9995  0.000129  0.000000  0.0  0.000000  0.0  0.000621  0.0  0.000000   \n",
      "9996  0.000000  0.000000  0.0  0.007666  0.0  0.001106  0.0  0.000000   \n",
      "9997  0.000164  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "9998  0.000256  0.000434  0.0  0.000000  0.0  0.000410  0.0  0.000433   \n",
      "9999  0.000152  0.000000  0.0  0.000000  0.0  0.000733  0.0  0.000000   \n",
      "\n",
      "           was  lau  ...       ffe  rro  alb  dop        l         ad  nym  \\\n",
      "0     0.000320  0.0  ...  0.000000  0.0  0.0  0.0  0.000504  0.000402  0.0   \n",
      "1     0.000529  0.0  ...  0.000000  0.0  0.0  0.0  0.000403  0.000884  0.0   \n",
      "2     0.000327  0.0  ...  0.000000  0.0  0.0  0.0  0.000327  0.000410  0.0   \n",
      "3     0.000000  0.0  ...  0.000000  0.0  0.0  0.0  0.000479  0.000000  0.0   \n",
      "4     0.000585  0.0  ...  0.000000  0.0  0.0  0.0  0.000167  0.000000  0.0   \n",
      "...        ...  ...  ...       ...  ...  ...  ...       ...       ...  ...   \n",
      "9995  0.000919  0.0  ...  0.000000  0.0  0.0  0.0  0.000657  0.000000  0.0   \n",
      "9996  0.000000  0.0  ...  0.000000  0.0  0.0  0.0  0.000000  0.004105  0.0   \n",
      "9997  0.000585  0.0  ...  0.000000  0.0  0.0  0.0  0.000335  0.000000  0.0   \n",
      "9998  0.000000  0.0  ...  0.000423  0.0  0.0  0.0  0.000173  0.000000  0.0   \n",
      "9999  0.000000  0.0  ...  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "\n",
      "           bul  unc  sli  \n",
      "0     0.000000  0.0  0.0  \n",
      "1     0.000000  0.0  0.0  \n",
      "2     0.000000  0.0  0.0  \n",
      "3     0.000000  0.0  0.0  \n",
      "4     0.000000  0.0  0.0  \n",
      "...        ...  ...  ...  \n",
      "9995  0.000000  0.0  0.0  \n",
      "9996  0.000000  0.0  0.0  \n",
      "9997  0.000000  0.0  0.0  \n",
      "9998  0.000765  0.0  0.0  \n",
      "9999  0.000000  0.0  0.0  \n",
      "\n",
      "[10000 rows x 2870 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Intersection = pd.DataFrame(Vectorizer_Intersection, columns = Vocabulary_Intersection)\n",
    "print (DataFrame_Intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_intersec, data_test_intersec, label_train_intersec, label_test_intersec = train_test_split((Vectorizer_Intersection), Label_Yelp, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Akurasi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skor Intersec_Model: 0.8312\n"
     ]
    }
   ],
   "source": [
    "RF_Classifier_Intersec = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Intersec.fit(data_train_intersec, label_train_intersec)\n",
    "print(\"skor Intersec_Model: {}\".format(RF_Classifier_Intersec.score(data_test_intersec, label_test_intersec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Jika diterapkan data gabungan antara Vocabulary_Amazon (fi > 0) dan Vocabulary Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary_Gabungan = []\n",
    "iterator = 0\n",
    "length = len(Vocabulary_Yelp)\n",
    "\n",
    "while iterator < length : \n",
    "#     jika interseksi dengan amazon dan bukan fitur importance maka vocab tidak dimasukan\n",
    "    if  (Vocabulary_Yelp[iterator] in Vocabulary_Amazon) and (Vocabulary_Yelp[iterator] not in Vocabulary_Importance_Amazon) : \n",
    "        iterator = iterator + 1\n",
    "        continue\n",
    "        \n",
    "    Vocabulary_Gabungan.append(Vocabulary_Yelp[iterator])\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordDictionaryCount_Gabungan = []\n",
    "\n",
    "iterator = 0\n",
    "while iterator < len(ngram_yelp):\n",
    "    WordDictionaryCount_Gabungan.append(dict.fromkeys(Vocabulary_Gabungan, 0))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "while iterator < len(ngram_yelp) :\n",
    "    for gram in ngram_yelp[iterator] :\n",
    "        if gram in Vocabulary_Gabungan :\n",
    "            WordDictionaryCount_Gabungan[iterator][gram] += 1\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "TF_Gabungan = []\n",
    "while iterator < len(WordDictionaryCount_Gabungan):\n",
    "    TF_Gabungan.append(computeTF(WordDictionaryCount_Gabungan[iterator], ngram_yelp[iterator]))\n",
    "    iterator = iterator + 1\n",
    "\n",
    "IDF_Gabungan = computeIDF(WordDictionaryCount_Gabungan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_Gabungan = []\n",
    "iterator = 0\n",
    "while iterator < len(WordDictionaryCount_Gabungan):\n",
    "    TF_IDF_Gabungan.append(computeTFIDF(TF_Gabungan[iterator], IDF_Gabungan))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer_Gabungan = []\n",
    "iterator  = 0\n",
    "while iterator < len(TF_IDF_Gabungan):\n",
    "    Vectorizer_Gabungan.append(list(TF_IDF_Gabungan[iterator].values()))\n",
    "    iterator = iterator + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            i          d        do        on        nt        t          k  \\\n",
      "0     0.000184  0.000388  0.000692  0.000343  0.000248  0.000095  0.000200   \n",
      "1     0.000506  0.000272  0.000761  0.000290  0.000508  0.000116  0.000220   \n",
      "2     0.000187  0.000216  0.000352  0.000376  0.000362  0.000143  0.000000   \n",
      "3     0.000096  0.000443  0.000483  0.000276  0.000149  0.000178  0.000000   \n",
      "4     0.000000  0.000129  0.000421  0.000289  0.000778  0.000201  0.000000   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  0.000395  0.000101  0.000000  0.000151  0.000102  0.000043  0.000572   \n",
      "9996  0.000000  0.000000  0.000000  0.000000  0.000000  0.000204  0.000000   \n",
      "9997  0.001175  0.000129  0.000000  0.000096  0.000130  0.000146  0.000729   \n",
      "9998  0.000217  0.000200  0.000218  0.000225  0.000604  0.000080  0.000189   \n",
      "9999  0.000933  0.000119  0.000390  0.000089  0.000240  0.000085  0.000000   \n",
      "\n",
      "            kn        no        ow  ...  pkg  zaf   fj  wlr  srx  xns  hnf  \\\n",
      "0     0.000294  0.000337  0.000101  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1     0.000323  0.000074  0.000111  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2     0.000000  0.000275  0.000411  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3     0.000000  0.000282  0.000211  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4     0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "9995  0.000000  0.000000  0.000289  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9996  0.000000  0.000000  0.001030  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9997  0.001073  0.000246  0.000368  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9998  0.000556  0.000127  0.000191  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "9999  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      lny  cpn  wfs  \n",
      "0     0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.0  \n",
      "...   ...  ...  ...  \n",
      "9995  0.0  0.0  0.0  \n",
      "9996  0.0  0.0  0.0  \n",
      "9997  0.0  0.0  0.0  \n",
      "9998  0.0  0.0  0.0  \n",
      "9999  0.0  0.0  0.0  \n",
      "\n",
      "[10000 rows x 4263 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFrame_Gabungan = pd.DataFrame(Vectorizer_Gabungan, columns = Vocabulary_Gabungan)\n",
    "print(DataFrame_Gabungan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_gabungan, data_test_gabungan, label_train_gabungan, label_test_gabungan = train_test_split((Vectorizer_Gabungan), Label_Yelp, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skor Model: 0.8296\n"
     ]
    }
   ],
   "source": [
    "RF_Classifier_Gabungan = RandomForestClassifier(max_depth= 5, n_estimators = 800, random_state=42,\n",
    "                                       bootstrap = False, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto')\n",
    "RF_Classifier_Gabungan.fit(data_train_gabungan, label_train_gabungan)\n",
    "print(\"skor Model: {}\".format(RF_Classifier_Gabungan.score(data_test_gabungan, label_test_gabungan)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
